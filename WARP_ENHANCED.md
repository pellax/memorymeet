# Proyecto Warp: Principios de Arquitectura y Buenas Pr√°cticas

## Contexto del Proyecto

**M2PRD-001: Meet-Teams-to-PRD** es un sistema distribuido Python/JavaScript que transforma grabaciones de audio de reuniones en documentos PRD estructurados y tareas asignadas autom√°ticamente. Utiliza una arquitectura de microservicios con orquestaci√≥n centralizada (n8n/Make), procesamiento IA/NLP (Python), persistencia pol√≠glota (PostgreSQL/Redis/MongoDB) y despliegue h√≠brido (Serverless/Contenedores).

---

## 1. Principios de Dise√±o: SOLID y KISS

### 1.1. Single Responsibility Principle (SRP)

**Aplicaci√≥n en M2PRD-001:**
- **M√≥dulo IA/NLP**: Se enfoca exclusivamente en procesamiento de lenguaje natural
- **Extensi√≥n Chrome**: Responsabilidad √∫nica de capturar eventos de reuniones
- **Webhook Service**: Solo recibe y valida requests HTTP
- **Orquestador (n8n/Make)**: √önicamente coordina flujos de trabajo

**Implementaci√≥n Pr√°ctica:**
```python
# ‚ùå VIOLACI√ìN SRP - Clase con m√∫ltiples responsabilidades
class MeetingProcessor:
    def capture_audio(self): pass
    def transcribe_audio(self): pass
    def generate_prd(self): pass
    def assign_tasks(self): pass
    def send_notifications(self): pass

# ‚úÖ CUMPLE SRP - Responsabilidades separadas
class AudioCaptureService:
    def capture_audio_from_meeting(self, meeting_url): pass

class TranscriptionService:
    def transcribe_audio(self, audio_file): pass

class PRDGenerationService:
    def generate_prd(self, transcription): pass

class TaskAssignmentService:
    def assign_tasks_to_roles(self, requirements): pass
```

### 1.2. Open/Closed Principle (OCP)

**Implementaci√≥n para RF5.0 - Integraci√≥n con PMS:**
```python
from abc import ABC, abstractmethod

# ‚úÖ CUMPLE OCP - Extensible sin modificaci√≥n
class PMSIntegration(ABC):
    @abstractmethod
    def create_task(self, requirement: Requisito) -> TareaAsignada:
        pass

class JiraIntegration(PMSIntegration):
    def create_task(self, requirement: Requisito) -> TareaAsignada:
        # Implementaci√≥n espec√≠fica para Jira
        pass

class TrelloIntegration(PMSIntegration):
    def create_task(self, requirement: Requisito) -> TareaAsignada:
        # Implementaci√≥n espec√≠fica para Trello
        pass

class LinearIntegration(PMSIntegration):
    def create_task(self, requirement: Requisito) -> TareaAsignada:
        # Nueva integraci√≥n sin modificar c√≥digo existente
        pass

# Factory Pattern para extensibilidad
class PMSIntegrationFactory:
    _integrations = {
        'jira': JiraIntegration,
        'trello': TrelloIntegration,
        'linear': LinearIntegration
    }
    
    @classmethod
    def create_integration(cls, pms_type: str) -> PMSIntegration:
        return cls._integrations[pms_type]()
```

### 1.3. Liskov Substitution Principle (LSP)

**Aplicaci√≥n en Jerarqu√≠a de Requisitos:**
```python
class Requisito(ABC):
    def __init__(self, descripcion: str, prioridad: str):
        self.descripcion = descripcion
        self.prioridad = prioridad
    
    @abstractmethod
    def generar_tarea(self) -> TareaAsignada:
        pass

class RequisitoFuncional(Requisito):
    def generar_tarea(self) -> TareaAsignada:
        # ‚úÖ CUMPLE LSP - Comportamiento consistente con clase base
        return TareaAsignada(
            tipo="funcional",
            descripcion=self.descripcion,
            prioridad=self.prioridad
        )

class RequisitoNoFuncional(Requisito):
    def generar_tarea(self) -> TareaAsignada:
        # ‚úÖ CUMPLE LSP - Comportamiento consistente con clase base
        return TareaAsignada(
            tipo="no_funcional", 
            descripcion=self.descripcion,
            prioridad=self.prioridad
        )
```

### 1.4. Interface Segregation Principle (ISP)

**Interfaces Espec√≠ficas para Diferentes Responsabilidades:**
```python
# ‚úÖ CUMPLE ISP - Interfaces espec√≠ficas y cohesivas
class AudioProcessable(Protocol):
    def process_audio(self, audio_data: bytes) -> str:
        pass

class TextAnalyzable(Protocol):
    def extract_requirements(self, text: str) -> List[Requisito]:
        pass

class TaskAssignable(Protocol):
    def assign_to_role(self, requirement: Requisito) -> str:
        pass

class NotificationSender(Protocol):
    def send_notification(self, message: str, recipient: str):
        pass

# Implementaci√≥n que solo depende de interfaces necesarias
class PRDGenerationService:
    def __init__(
        self, 
        text_analyzer: TextAnalyzable,
        task_assigner: TaskAssignable,
        notifier: NotificationSender
    ):
        # ‚úÖ Solo depende de interfaces que realmente usa
        self.text_analyzer = text_analyzer
        self.task_assigner = task_assigner  
        self.notifier = notifier
```

### 1.5. Dependency Inversion Principle (DIP)

**Implementaci√≥n con Inversi√≥n de Control:**
```python
# ‚úÖ CUMPLE DIP - Depende de abstracciones, no de concreciones
class WorkflowOrchestrator:
    def __init__(
        self,
        transcription_service: TranscriptionService,  # Abstracci√≥n
        prd_generator: PRDGenerationService,         # Abstracci√≥n  
        pms_integration: PMSIntegration,             # Abstracci√≥n
        secret_manager: SecretManager                # Abstracci√≥n
    ):
        self.transcription_service = transcription_service
        self.prd_generator = prd_generator
        self.pms_integration = pms_integration
        self.secret_manager = secret_manager

    def process_meeting(self, meeting_data: dict) -> ProcessingResult:
        # ‚úÖ Usa abstracciones, permite testing y flexibilidad
        api_key = self.secret_manager.get_secret("DEEPGRAM_API_KEY")
        transcription = self.transcription_service.transcribe(
            meeting_data['audio_url'], 
            api_key
        )
        prd = self.prd_generator.generate_prd(transcription)
        tasks = self.pms_integration.create_tasks(prd.requirements)
        return ProcessingResult(prd=prd, tasks=tasks)
```

### 1.6. KISS Principle (Keep It Simple, Stupid)

**Aplicaci√≥n en Dise√±o de Componentes:**
```python
# ‚ùå VIOLACI√ìN KISS - Complejidad innecesaria
class ComplexMeetingProcessor:
    def process_with_multiple_algorithms(self, audio):
        # Implementaci√≥n con m√∫ltiples algoritmos, caching complejo,
        # optimizaciones prematuras, configuraciones excesivas
        pass

# ‚úÖ CUMPLE KISS - Implementaci√≥n simple y directa
class MeetingProcessor:
    def __init__(self, transcription_service: TranscriptionService):
        self.transcription_service = transcription_service
    
    def process_meeting(self, audio_url: str) -> PRD:
        """Procesa una reuni√≥n de forma simple y directa."""
        transcription = self.transcription_service.transcribe(audio_url)
        requirements = self._extract_requirements(transcription)
        return self._generate_prd(requirements)
    
    def _extract_requirements(self, transcription: str) -> List[Requisito]:
        # Implementaci√≥n simple usando bibliotecas est√°ndar
        pass
    
    def _generate_prd(self, requirements: List[Requisito]) -> PRD:
        # Generaci√≥n directa del PRD
        pass
```

---

## 2. Estrategias de Arquitectura: Clean Architecture

### 2.1. Capas de Clean Architecture

**Aplicaci√≥n en M2PRD-001:**

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ UI/Controllers (Presentation Layer)         ‚îÇ
‚îÇ ‚Ä¢ Chrome Extension                          ‚îÇ
‚îÇ ‚Ä¢ Webhook Endpoints                         ‚îÇ
‚îÇ ‚Ä¢ n8n/Make Workflows                        ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ Application Services (Use Cases)            ‚îÇ
‚îÇ ‚Ä¢ ProcessMeetingUseCase                     ‚îÇ
‚îÇ ‚Ä¢ GeneratePRDUseCase                        ‚îÇ
‚îÇ ‚Ä¢ AssignTasksUseCase                        ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ Domain Layer (Business Logic)               ‚îÇ
‚îÇ ‚Ä¢ Entities: Reunion, PRD, Requisito        ‚îÇ
‚îÇ ‚Ä¢ Value Objects: AudioFile, Transcripcion  ‚îÇ
‚îÇ ‚Ä¢ Domain Services: RequirementClassifier   ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ Infrastructure Layer                        ‚îÇ
‚îÇ ‚Ä¢ Database: PostgreSQL, Redis, MongoDB     ‚îÇ
‚îÇ ‚Ä¢ External APIs: Deepgram, Jira, Linear    ‚îÇ
‚îÇ ‚Ä¢ Cloud Services: AWS Lambda, GCF          ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

### 2.2. Implementaci√≥n de Casos de Uso

```python
# ‚úÖ CLEAN ARCHITECTURE - Caso de uso bien definido
class ProcessMeetingUseCase:
    def __init__(
        self,
        meeting_repository: MeetingRepository,          # Puerto
        transcription_service: TranscriptionService,   # Puerto
        prd_generator: PRDGenerationService,           # Puerto
        task_repository: TaskRepository,               # Puerto
        event_publisher: EventPublisher                # Puerto
    ):
        self._meeting_repository = meeting_repository
        self._transcription_service = transcription_service
        self._prd_generator = prd_generator
        self._task_repository = task_repository
        self._event_publisher = event_publisher

    def execute(self, command: ProcessMeetingCommand) -> ProcessMeetingResponse:
        # 1. Validar entrada
        self._validate_command(command)
        
        # 2. Recuperar reuni√≥n
        meeting = self._meeting_repository.get_by_id(command.meeting_id)
        
        # 3. Procesar audio (delegado a servicio de dominio)
        transcription = self._transcription_service.transcribe(meeting.audio_url)
        
        # 4. Generar PRD
        prd = self._prd_generator.generate(transcription)
        
        # 5. Crear tareas
        tasks = self._create_tasks_from_requirements(prd.requirements)
        
        # 6. Persistir resultados
        self._task_repository.save_all(tasks)
        
        # 7. Publicar evento de finalizaci√≥n
        self._event_publisher.publish(
            MeetingProcessedEvent(
                meeting_id=command.meeting_id,
                prd_id=prd.id,
                task_ids=[task.id for task in tasks]
            )
        )
        
        return ProcessMeetingResponse(
            success=True,
            prd=prd,
            tasks=tasks,
            processing_time=self._calculate_processing_time()
        )
```

### 2.3. Entidades de Dominio

```python
# ‚úÖ CLEAN ARCHITECTURE - Entidades ricas en comportamiento
from dataclasses import dataclass
from typing import List, Optional
from enum import Enum

class RequirementType(Enum):
    FUNCTIONAL = "funcional"
    NON_FUNCTIONAL = "no_funcional"

class Priority(Enum):
    P0 = "P0"  # Cr√≠tico
    P1 = "P1"  # Alto
    P2 = "P2"  # Medio

@dataclass
class Requisito:
    """Entidad de dominio para requisitos."""
    id_requisito: str
    tipo: RequirementType
    descripcion: str
    prioridad: Priority
    
    def generar_tarea(self, assignee_resolver: 'AssigneeResolver') -> 'TareaAsignada':
        """L√≥gica de dominio para generar tareas."""
        assignee = assignee_resolver.resolve_assignee_for_requirement(self)
        
        return TareaAsignada(
            id_tarea=self._generate_task_id(),
            requisito_id=self.id_requisito,
            assignee=assignee,
            estado="PENDIENTE",
            prioridad=self.prioridad.value
        )
    
    def _generate_task_id(self) -> str:
        """Genera ID √∫nico para la tarea."""
        import uuid
        return f"TASK-{uuid.uuid4().hex[:8]}"

@dataclass  
class PRD:
    """Agregado ra√≠z para PRD."""
    id: str
    titulo: str
    fecha_creacion: datetime
    requirements: List[Requisito]
    
    def add_requirement(self, requirement: Requisito) -> None:
        """Invariante de dominio: PRD debe tener al menos un requisito."""
        self.requirements.append(requirement)
    
    def generar_todas_las_tareas(self, assignee_resolver: 'AssigneeResolver') -> List['TareaAsignada']:
        """L√≥gica de dominio para generar todas las tareas."""
        if not self.requirements:
            raise DomainException("PRD debe tener al menos un requisito para generar tareas")
            
        return [req.generar_tarea(assignee_resolver) for req in self.requirements]
    
    def generar_pdf(self) -> bytes:
        """Generaci√≥n del documento PDF."""
        # L√≥gica de dominio para generar PDF
        pass
```

### 2.4. Ports & Adapters (Hexagonal Architecture)

```python
# ‚úÖ PORTS & ADAPTERS - Definici√≥n de puertos
from abc import ABC, abstractmethod

# PUERTOS (Interfaces)
class TranscriptionService(ABC):
    @abstractmethod
    def transcribe(self, audio_url: str, api_key: str) -> str:
        pass

class SecretManager(ABC):
    @abstractmethod
    def get_secret(self, secret_name: str) -> str:
        pass

class PMSIntegration(ABC):
    @abstractmethod
    def create_task(self, task: TareaAsignada) -> str:
        pass

# ADAPTADORES (Implementaciones)
class DeepgramTranscriptionAdapter(TranscriptionService):
    def __init__(self, deepgram_client):
        self.client = deepgram_client
    
    def transcribe(self, audio_url: str, api_key: str) -> str:
        # ‚úÖ Implementaci√≥n espec√≠fica de Deepgram
        response = self.client.transcription.prerecorded(
            {'url': audio_url}, 
            {'punctuate': True, 'model': 'nova'}
        )
        return response['results']['channels'][0]['alternatives'][0]['transcript']

class AWSSecretsManagerAdapter(SecretManager):
    def __init__(self, aws_client):
        self.client = aws_client
    
    def get_secret(self, secret_name: str) -> str:
        # ‚úÖ Implementaci√≥n espec√≠fica de AWS
        response = self.client.get_secret_value(SecretId=secret_name)
        return response['SecretString']

class JiraIntegrationAdapter(PMSIntegration):
    def __init__(self, jira_client):
        self.client = jira_client
    
    def create_task(self, task: TareaAsignada) -> str:
        # ‚úÖ Implementaci√≥n espec√≠fica de Jira
        issue_data = {
            'project': {'key': 'PRD'},
            'summary': task.descripcion,
            'description': f"Requisito: {task.requisito_id}",
            'issuetype': {'name': 'Task'},
            'assignee': {'name': task.assignee},
            'priority': {'name': task.prioridad}
        }
        issue = self.client.create_issue(fields=issue_data)
        return issue.key
```

---

## 3. Patrones de Dise√±o Aplicados

### 3.1. Factory Pattern

**Aplicaci√≥n para RF4.0 - Asignaci√≥n Inteligente:**
```python
class RoleAssignmentFactory:
    """Factory para resolver asignaci√≥n de roles basado en tipo de requisito."""
    
    _role_mappings = {
        'ui_requirement': 'Frontend Developer',
        'api_requirement': 'Backend Developer', 
        'database_requirement': 'Backend Developer',
        'infrastructure_requirement': 'Cloud Engineer',
        'user_experience': 'UX Designer',
        'full_stack': 'Full Stack Developer'
    }
    
    @classmethod
    def get_assignee_for_requirement(cls, requisito: Requisito) -> str:
        requirement_type = cls._classify_requirement(requisito.descripcion)
        return cls._role_mappings.get(requirement_type, 'Full Stack Developer')
    
    @classmethod
    def _classify_requirement(cls, descripcion: str) -> str:
        # ‚úÖ Factory Method - L√≥gica de clasificaci√≥n centralizada
        descripcion_lower = descripcion.lower()
        
        if any(keyword in descripcion_lower for keyword in ['ui', 'interface', 'frontend', 'react']):
            return 'ui_requirement'
        elif any(keyword in descripcion_lower for keyword in ['api', 'backend', 'server', 'python']):
            return 'api_requirement'
        elif any(keyword in descripcion_lower for keyword in ['database', 'postgresql', 'redis']):
            return 'database_requirement'
        elif any(keyword in descripcion_lower for keyword in ['cloud', 'aws', 'docker', 'kubernetes']):
            return 'infrastructure_requirement'
        elif any(keyword in descripcion_lower for keyword in ['ux', 'user', 'design', 'usability']):
            return 'user_experience'
        else:
            return 'full_stack'
```

### 3.2. Strategy Pattern

**Aplicaci√≥n para Diferentes Algoritmos de NLP:**
```python
from abc import ABC, abstractmethod

class RequirementExtractionStrategy(ABC):
    @abstractmethod
    def extract_requirements(self, transcription: str) -> List[Requisito]:
        pass

class SpacyRequirementExtractor(RequirementExtractionStrategy):
    def __init__(self, nlp_model):
        self.nlp = nlp_model
    
    def extract_requirements(self, transcription: str) -> List[Requisito]:
        # ‚úÖ STRATEGY - Implementaci√≥n espec√≠fica con spaCy
        doc = self.nlp(transcription)
        requirements = []
        
        for sent in doc.sents:
            if self._is_requirement_sentence(sent):
                req = self._create_requirement_from_sentence(sent)
                requirements.append(req)
        
        return requirements

class OpenAIRequirementExtractor(RequirementExtractionStrategy):
    def __init__(self, openai_client):
        self.client = openai_client
    
    def extract_requirements(self, transcription: str) -> List[Requisito]:
        # ‚úÖ STRATEGY - Implementaci√≥n espec√≠fica con OpenAI
        prompt = f"""
        Extrae los requisitos funcionales y no funcionales de la siguiente transcripci√≥n:
        {transcription}
        
        Formato JSON: [{{"tipo": "funcional|no_funcional", "descripcion": "...", "prioridad": "P0|P1|P2"}}]
        """
        
        response = self.client.chat.completions.create(
            model="gpt-4",
            messages=[{"role": "user", "content": prompt}]
        )
        
        return self._parse_openai_response(response)

# Context que usa las estrategias
class PRDGenerationService:
    def __init__(self, extraction_strategy: RequirementExtractionStrategy):
        self.extraction_strategy = extraction_strategy
    
    def generate_prd(self, transcription: str) -> PRD:
        # ‚úÖ STRATEGY - El contexto delega la extracci√≥n a la estrategia
        requirements = self.extraction_strategy.extract_requirements(transcription)
        
        return PRD(
            id=self._generate_prd_id(),
            titulo=self._extract_title_from_transcription(transcription),
            fecha_creacion=datetime.now(),
            requirements=requirements
        )
```

### 3.3. Observer Pattern

**Aplicaci√≥n para Notificaciones (RF - Notificar al PM):**
```python
from abc import ABC, abstractmethod
from typing import List

class MeetingProcessingObserver(ABC):
    @abstractmethod
    def on_processing_started(self, meeting_id: str):
        pass
    
    @abstractmethod
    def on_processing_completed(self, meeting_id: str, prd: PRD, tasks: List[TareaAsignada]):
        pass
    
    @abstractmethod 
    def on_processing_failed(self, meeting_id: str, error: Exception):
        pass

class EmailNotificationObserver(MeetingProcessingObserver):
    def __init__(self, email_service: EmailService):
        self.email_service = email_service
    
    def on_processing_started(self, meeting_id: str):
        # ‚úÖ OBSERVER - Notificaci√≥n espec√≠fica por email
        self.email_service.send_email(
            subject=f"Procesamiento iniciado - Reuni√≥n {meeting_id}",
            body="El procesamiento de la reuni√≥n ha comenzado...",
            recipients=self._get_pm_emails()
        )
    
    def on_processing_completed(self, meeting_id: str, prd: PRD, tasks: List[TareaAsignada]):
        # ‚úÖ OBSERVER - Notificaci√≥n de finalizaci√≥n exitosa
        task_summary = self._create_task_summary(tasks)
        self.email_service.send_email(
            subject=f"PRD y tareas listos - Reuni√≥n {meeting_id}",
            body=f"PRD generado: {prd.titulo}\nTareas creadas: {task_summary}",
            recipients=self._get_pm_emails(),
            attachments=[prd.generar_pdf()]
        )

class SlackNotificationObserver(MeetingProcessingObserver):
    def __init__(self, slack_client):
        self.slack_client = slack_client
    
    def on_processing_completed(self, meeting_id: str, prd: PRD, tasks: List[TareaAsignada]):
        # ‚úÖ OBSERVER - Notificaci√≥n espec√≠fica por Slack
        message = f"""
        ‚úÖ Reuni√≥n {meeting_id} procesada exitosamente
        üìÑ PRD: {prd.titulo}
        üìã Tareas creadas: {len(tasks)}
        """
        self.slack_client.send_message(channel="#pm-notifications", message=message)

# Subject (Observable)
class MeetingProcessor:
    def __init__(self):
        self._observers: List[MeetingProcessingObserver] = []
    
    def add_observer(self, observer: MeetingProcessingObserver):
        self._observers.append(observer)
    
    def remove_observer(self, observer: MeetingProcessingObserver):
        self._observers.remove(observer)
    
    def _notify_processing_started(self, meeting_id: str):
        for observer in self._observers:
            observer.on_processing_started(meeting_id)
    
    def _notify_processing_completed(self, meeting_id: str, prd: PRD, tasks: List[TareaAsignada]):
        for observer in self._observers:
            observer.on_processing_completed(meeting_id, prd, tasks)
    
    def process_meeting(self, meeting_id: str) -> ProcessingResult:
        self._notify_processing_started(meeting_id)
        
        try:
            # L√≥gica de procesamiento...
            prd = self._generate_prd()
            tasks = self._create_tasks()
            
            self._notify_processing_completed(meeting_id, prd, tasks)
            return ProcessingResult(success=True, prd=prd, tasks=tasks)
            
        except Exception as e:
            self._notify_processing_failed(meeting_id, e)
            raise
```

### 3.4. Circuit Breaker Pattern

**Aplicaci√≥n para RNF5.0 - Tolerancia a Fallos:**
```python
import time
from enum import Enum
from typing import Callable, Any

class CircuitState(Enum):
    CLOSED = "closed"      # Funcionando normalmente
    OPEN = "open"          # Circuito abierto, fallos detectados  
    HALF_OPEN = "half_open" # Probando si el servicio se recuper√≥

class CircuitBreaker:
    def __init__(
        self, 
        failure_threshold: int = 5,
        timeout: int = 60,
        expected_exception: type = Exception
    ):
        self.failure_threshold = failure_threshold
        self.timeout = timeout
        self.expected_exception = expected_exception
        
        self.failure_count = 0
        self.last_failure_time = None
        self.state = CircuitState.CLOSED
    
    def call(self, func: Callable, *args, **kwargs) -> Any:
        """‚úÖ CIRCUIT BREAKER - Protege llamadas a servicios externos."""
        
        if self.state == CircuitState.OPEN:
            if self._should_attempt_reset():
                self.state = CircuitState.HALF_OPEN
            else:
                raise CircuitBreakerOpenException("Circuit breaker is OPEN")
        
        try:
            result = func(*args, **kwargs)
            self._on_success()
            return result
            
        except self.expected_exception as e:
            self._on_failure()
            raise e
    
    def _should_attempt_reset(self) -> bool:
        return (time.time() - self.last_failure_time) >= self.timeout
    
    def _on_success(self):
        self.failure_count = 0
        self.state = CircuitState.CLOSED
    
    def _on_failure(self):
        self.failure_count += 1
        self.last_failure_time = time.time()
        
        if self.failure_count >= self.failure_threshold:
            self.state = CircuitState.OPEN

# Aplicaci√≥n en servicios externos
class RobustTranscriptionService:
    def __init__(self, transcription_service: TranscriptionService):
        self.service = transcription_service
        self.circuit_breaker = CircuitBreaker(
            failure_threshold=3,  # RNF5.0: M√°ximo 3 reintentos
            timeout=60,           # RNF5.0: Esperar 1 minuto
            expected_exception=TranscriptionServiceException
        )
    
    def transcribe_with_protection(self, audio_url: str, api_key: str) -> str:
        """‚úÖ Transcripci√≥n protegida por Circuit Breaker."""
        return self.circuit_breaker.call(
            self.service.transcribe, 
            audio_url, 
            api_key
        )
```

---

## 4. Bases de Datos: Principios ACID

### 4.1. Implementaci√≥n de Transacciones ACID

```python
from contextlib import contextmanager
from sqlalchemy import create_engine
from sqlalchemy.orm import sessionmaker, Session
from typing import Generator

class DatabaseTransactionManager:
    """‚úÖ ACID - Gestor de transacciones que garantiza propiedades ACID."""
    
    def __init__(self, database_url: str):
        self.engine = create_engine(database_url)
        self.SessionLocal = sessionmaker(bind=self.engine)
    
    @contextmanager
    def transaction(self) -> Generator[Session, None, None]:
        """
        ‚úÖ ACID - Context manager que garantiza:
        - Atomicity: Todo o nada
        - Consistency: Reglas de integridad
        - Isolation: Transacciones aisladas  
        - Durability: Cambios persistentes
        """
        session = self.SessionLocal()
        try:
            yield session
            session.commit()  # ‚úÖ ATOMICITY & DURABILITY
        except Exception as e:
            session.rollback()  # ‚úÖ ATOMICITY - Rollback en caso de error
            raise e
        finally:
            session.close()

class MeetingRepository:
    def __init__(self, db_manager: DatabaseTransactionManager):
        self.db_manager = db_manager
    
    def save_meeting_with_prd_and_tasks(
        self, 
        meeting: Reunion, 
        prd: PRD, 
        tasks: List[TareaAsignada]
    ) -> None:
        """‚úÖ ACID - Operaci√≥n at√≥mica completa."""
        
        with self.db_manager.transaction() as session:
            # ‚úÖ CONSISTENCY - Validaciones de integridad
            self._validate_meeting_data(meeting)
            self._validate_prd_data(prd)
            self._validate_tasks_data(tasks)
            
            # ‚úÖ ATOMICITY - Todo en una transacci√≥n
            session.add(meeting)
            session.add(prd)
            session.add_all(tasks)
            
            # ‚úÖ CONSISTENCY - Relaciones consistentes
            prd.reunion_id = meeting.id
            for task in tasks:
                task.prd_id = prd.id
            
            # ‚úÖ ISOLATION - La transacci√≥n se ejecuta de forma aislada
            # ‚úÖ DURABILITY - Los cambios persisten al hacer commit
    
    def _validate_meeting_data(self, meeting: Reunion) -> None:
        """‚úÖ CONSISTENCY - Validaciones de reglas de negocio."""
        if not meeting.url_audio:
            raise ValueError("Meeting must have audio URL")
        if not meeting.id_reunion:
            raise ValueError("Meeting must have valid ID")
    
    def _validate_prd_data(self, prd: PRD) -> None:
        """‚úÖ CONSISTENCY - Validaciones de PRD."""
        if not prd.requirements:
            raise ValueError("PRD must have at least one requirement")
        if len(prd.titulo) < 5:
            raise ValueError("PRD title must be at least 5 characters")
    
    def _validate_tasks_data(self, tasks: List[TareaAsignada]) -> None:
        """‚úÖ CONSISTENCY - Validaciones de tareas."""
        valid_roles = ['Frontend Developer', 'Backend Developer', 'Full Stack Developer', 'Cloud Engineer', 'UX Designer']
        
        for task in tasks:
            if task.pm_asignado not in valid_roles:
                raise ValueError(f"Invalid role assignment: {task.pm_asignado}")
```

### 4.2. Gesti√≥n de Concurrent Access

```python
from sqlalchemy import select, text
from sqlalchemy.exc import IntegrityError
import redis

class ConcurrentMeetingProcessor:
    """‚úÖ ACID - Gesti√≥n de concurrencia para procesamiento de reuniones."""
    
    def __init__(self, db_manager: DatabaseTransactionManager, redis_client: redis.Redis):
        self.db_manager = db_manager
        self.redis = redis_client
    
    def process_meeting_safely(self, meeting_id: str) -> ProcessingResult:
        """‚úÖ ISOLATION - Procesa reuni√≥n evitando condiciones de carrera."""
        
        lock_key = f"meeting_processing:{meeting_id}"
        
        # ‚úÖ ISOLATION - Lock distribuido para evitar procesamiento concurrente
        with self.redis.lock(lock_key, timeout=300):  # 5 minutos timeout
            
            with self.db_manager.transaction() as session:
                # ‚úÖ ISOLATION - Select con FOR UPDATE evita lecturas sucias
                meeting = session.execute(
                    select(Meeting)
                    .where(Meeting.id == meeting_id)
                    .with_for_update()  # Bloqueo pesimista
                ).scalar_one_or_none()
                
                if not meeting:
                    raise MeetingNotFoundException(f"Meeting {meeting_id} not found")
                
                if meeting.status == 'PROCESSING':
                    raise MeetingAlreadyProcessingException(
                        f"Meeting {meeting_id} is already being processed"
                    )
                
                # ‚úÖ CONSISTENCY - Actualizaci√≥n at√≥mica de estado
                meeting.status = 'PROCESSING'
                meeting.processing_started_at = datetime.utcnow()
                
                try:
                    # Procesamiento de la reuni√≥n
                    result = self._do_processing(meeting)
                    
                    # ‚úÖ ATOMICITY - Todo o nada
                    meeting.status = 'COMPLETED'
                    meeting.processing_completed_at = datetime.utcnow()
                    
                    return result
                    
                except Exception as e:
                    # ‚úÖ CONSISTENCY - Estado consistente en caso de error
                    meeting.status = 'FAILED'
                    meeting.error_message = str(e)
                    raise e
```

---

## 5. Gesti√≥n de Calidad de C√≥digo

### 5.1. Clean Code Principles

```python
# ‚úÖ CLEAN CODE - Nombres descriptivos y funciones peque√±as
class MeetingAudioProcessor:
    """Procesador de audio de reuniones con principios de Clean Code."""
    
    def process_meeting_audio(self, meeting_url: str) -> ProcessingResult:
        """
        ‚úÖ CLEAN CODE - Funci√≥n con una sola responsabilidad y nombre descriptivo.
        
        Args:
            meeting_url: URL de la reuni√≥n a procesar
            
        Returns:
            ProcessingResult: Resultado del procesamiento con PRD y tareas
            
        Raises:
            InvalidMeetingUrlException: Si la URL no es v√°lida
            TranscriptionFailedException: Si falla la transcripci√≥n
        """
        self._validate_meeting_url(meeting_url)
        
        audio_file = self._extract_audio_from_meeting(meeting_url)
        transcription = self._transcribe_audio_safely(audio_file)
        requirements = self._extract_requirements_from_transcription(transcription)
        prd = self._generate_prd_from_requirements(requirements)
        tasks = self._create_tasks_from_prd(prd)
        
        return ProcessingResult(prd=prd, tasks=tasks)
    
    def _validate_meeting_url(self, url: str) -> None:
        """‚úÖ CLEAN CODE - Funci√≥n peque√±a con prop√≥sito espec√≠fico."""
        if not url or not self._is_valid_meeting_url(url):
            raise InvalidMeetingUrlException(f"Invalid meeting URL: {url}")
    
    def _is_valid_meeting_url(self, url: str) -> bool:
        """‚úÖ CLEAN CODE - Funci√≥n booleana con nombre claro."""
        valid_patterns = [
            r'https://meet\.google\.com/',
            r'https://teams\.microsoft\.com/',
            r'https://zoom\.us/'
        ]
        return any(re.match(pattern, url) for pattern in valid_patterns)
    
    def _extract_audio_from_meeting(self, meeting_url: str) -> AudioFile:
        """‚úÖ CLEAN CODE - Abstracci√≥n clara del proceso."""
        # Implementaci√≥n espec√≠fica extra√≠da a m√©todo privado
        pass
    
    def _transcribe_audio_safely(self, audio_file: AudioFile) -> Transcription:
        """‚úÖ CLEAN CODE - Manejo de errores expl√≠cito en el nombre."""
        max_retries = 3
        retry_count = 0
        
        while retry_count < max_retries:
            try:
                return self.transcription_service.transcribe(audio_file)
            except TranscriptionServiceException as e:
                retry_count += 1
                if retry_count >= max_retries:
                    raise TranscriptionFailedException(
                        f"Failed to transcribe after {max_retries} attempts"
                    ) from e
                self._wait_before_retry(retry_count)
    
    def _wait_before_retry(self, retry_count: int) -> None:
        """‚úÖ CLEAN CODE - Responsabilidad espec√≠fica extra√≠da."""
        wait_time = min(60, 2 ** retry_count)  # Exponential backoff, max 60s
        time.sleep(wait_time)
```

### 5.2. Logging y Observabilidad

```python
import logging
import structlog
from contextlib import contextmanager
import time
from typing import Dict, Any

# ‚úÖ CLEAN CODE - Configuraci√≥n centralizada de logging
def configure_structured_logging():
    """Configura logging estructurado para mejor observabilidad."""
    structlog.configure(
        processors=[
            structlog.stdlib.filter_by_level,
            structlog.stdlib.add_logger_name,
            structlog.stdlib.add_log_level,
            structlog.stdlib.PositionalArgumentsFormatter(),
            structlog.processors.TimeStamper(fmt="iso"),
            structlog.processors.StackInfoRenderer(),
            structlog.processors.format_exc_info,
            structlog.processors.UnicodeDecoder(),
            structlog.processors.JSONRenderer()
        ],
        context_class=dict,
        logger_factory=structlog.stdlib.LoggerFactory(),
        wrapper_class=structlog.stdlib.BoundLogger,
        cache_logger_on_first_use=True,
    )

class ObservableMeetingProcessor:
    """‚úÖ CLEAN CODE - Procesador con observabilidad integrada."""
    
    def __init__(self):
        self.logger = structlog.get_logger(__name__)
    
    def process_meeting(self, meeting_id: str) -> ProcessingResult:
        """‚úÖ OBSERVABILITY - Procesamiento con logs estructurados."""
        
        with self._log_processing_context(meeting_id) as ctx:
            try:
                self.logger.info(
                    "meeting_processing_started",
                    meeting_id=meeting_id,
                    component="meeting_processor"
                )
                
                # Procesamiento con m√©tricas
                with self._measure_processing_time() as timer:
                    result = self._do_processing(meeting_id)
                
                self.logger.info(
                    "meeting_processing_completed",
                    meeting_id=meeting_id,
                    processing_time_seconds=timer.elapsed,
                    prd_id=result.prd.id,
                    tasks_created=len(result.tasks),
                    component="meeting_processor"
                )
                
                return result
                
            except Exception as e:
                self.logger.error(
                    "meeting_processing_failed",
                    meeting_id=meeting_id,
                    error_type=type(e).__name__,
                    error_message=str(e),
                    component="meeting_processor",
                    exc_info=True
                )
                raise
    
    @contextmanager
    def _log_processing_context(self, meeting_id: str):
        """‚úÖ OBSERVABILITY - Context manager para logging contextual."""
        self.logger = self.logger.bind(meeting_id=meeting_id)
        try:
            yield self.logger
        finally:
            self.logger = self.logger.unbind("meeting_id")
    
    @contextmanager
    def _measure_processing_time(self):
        """‚úÖ OBSERVABILITY - Medici√≥n de tiempo de procesamiento."""
        class Timer:
            def __init__(self):
                self.start_time = time.time()
                self.elapsed = 0
        
        timer = Timer()
        try:
            yield timer
        finally:
            timer.elapsed = time.time() - timer.start_time
```

### 5.3. Testing Strategy

```python
import pytest
from unittest.mock import Mock, patch, MagicMock
from typing import Generator

# ‚úÖ CLEAN CODE - Tests bien estructurados y descriptivos
class TestMeetingProcessor:
    """‚úÖ TESTING - Suite de tests comprehensive."""
    
    @pytest.fixture
    def mock_transcription_service(self) -> Mock:
        """‚úÖ TESTING - Mock para servicio de transcripci√≥n."""
        mock = Mock(spec=TranscriptionService)
        mock.transcribe.return_value = "Mock transcription content"
        return mock
    
    @pytest.fixture
    def mock_prd_generator(self) -> Mock:
        """‚úÖ TESTING - Mock para generador de PRD."""
        mock = Mock(spec=PRDGenerationService)
        mock_prd = PRD(
            id="test-prd-1",
            titulo="Test PRD",
            fecha_creacion=datetime.now(),
            requirements=[
                Requisito(
                    id_requisito="req-1",
                    tipo=RequirementType.FUNCTIONAL,
                    descripcion="Test requirement",
                    prioridad=Priority.P1
                )
            ]
        )
        mock.generate_prd.return_value = mock_prd
        return mock
    
    @pytest.fixture
    def meeting_processor(
        self, 
        mock_transcription_service: Mock, 
        mock_prd_generator: Mock
    ) -> MeetingProcessor:
        """‚úÖ TESTING - Fixture para procesador con dependencias mockeadas."""
        return MeetingProcessor(
            transcription_service=mock_transcription_service,
            prd_generator=mock_prd_generator
        )
    
    def test_process_meeting_success_path(self, meeting_processor: MeetingProcessor):
        """‚úÖ TESTING - Test del camino exitoso."""
        # Given
        meeting_url = "https://meet.google.com/test-meeting"
        
        # When
        result = meeting_processor.process_meeting_audio(meeting_url)
        
        # Then
        assert result.success is True
        assert result.prd is not None
        assert result.prd.titulo == "Test PRD"
        assert len(result.tasks) == 1
        assert result.tasks[0].requisito_id == "req-1"
    
    def test_process_meeting_with_invalid_url_should_raise_exception(
        self, 
        meeting_processor: MeetingProcessor
    ):
        """‚úÖ TESTING - Test de validaci√≥n de entrada."""
        # Given
        invalid_url = "not-a-valid-url"
        
        # When & Then
        with pytest.raises(InvalidMeetingUrlException) as exc_info:
            meeting_processor.process_meeting_audio(invalid_url)
        
        assert "Invalid meeting URL" in str(exc_info.value)
    
    def test_process_meeting_with_transcription_failure_should_retry_and_fail(
        self,
        mock_transcription_service: Mock,
        meeting_processor: MeetingProcessor
    ):
        """‚úÖ TESTING - Test de manejo de errores y reintentos."""
        # Given  
        mock_transcription_service.transcribe.side_effect = TranscriptionServiceException("Service unavailable")
        meeting_url = "https://meet.google.com/test-meeting"
        
        # When & Then
        with pytest.raises(TranscriptionFailedException):
            meeting_processor.process_meeting_audio(meeting_url)
        
        # Verify retry behavior
        assert mock_transcription_service.transcribe.call_count == 3
    
    @patch('time.sleep')  # ‚úÖ TESTING - Mock de sleep para tests r√°pidos
    def test_retry_logic_uses_exponential_backoff(
        self,
        mock_sleep: Mock,
        mock_transcription_service: Mock,
        meeting_processor: MeetingProcessor
    ):
        """‚úÖ TESTING - Test de l√≥gica de backoff exponencial."""
        # Given
        mock_transcription_service.transcribe.side_effect = [
            TranscriptionServiceException("Retry 1"),
            TranscriptionServiceException("Retry 2"), 
            "Success on third try"
        ]
        meeting_url = "https://meet.google.com/test-meeting"
        
        # When
        result = meeting_processor.process_meeting_audio(meeting_url)
        
        # Then
        assert result.success is True
        assert mock_sleep.call_count == 2
        mock_sleep.assert_any_call(2)  # First retry: 2^1 = 2 seconds
        mock_sleep.assert_any_call(4)  # Second retry: 2^2 = 4 seconds

# ‚úÖ TESTING - Tests de integraci√≥n con base de datos
@pytest.mark.integration
class TestMeetingRepository:
    """‚úÖ TESTING - Tests de integraci√≥n para repositorio."""
    
    @pytest.fixture
    def db_session(self) -> Generator[Session, None, None]:
        """‚úÖ TESTING - Fixture para sesi√≥n de BD de prueba."""
        engine = create_engine("sqlite:///:memory:")
        Base.metadata.create_all(engine)
        SessionLocal = sessionmaker(bind=engine)
        
        session = SessionLocal()
        try:
            yield session
        finally:
            session.close()
    
    def test_save_meeting_with_prd_and_tasks_atomically(self, db_session: Session):
        """‚úÖ TESTING - Test de transacci√≥n at√≥mica."""
        # Given
        meeting = Meeting(id="test-meeting", url_audio="http://example.com/audio.mp3")
        prd = PRD(id="test-prd", titulo="Test PRD", fecha_creacion=datetime.now())
        tasks = [
            TareaAsignada(id_tarea="task-1", pm_asignado="Backend Developer"),
            TareaAsignada(id_tarea="task-2", pm_asignado="Frontend Developer")
        ]
        
        repository = MeetingRepository(db_session)
        
        # When
        repository.save_meeting_with_prd_and_tasks(meeting, prd, tasks)
        
        # Then - Verify all data was saved
        saved_meeting = db_session.get(Meeting, "test-meeting")
        saved_prd = db_session.get(PRD, "test-prd") 
        saved_tasks = db_session.query(TareaAsignada).filter(
            TareaAsignada.prd_id == "test-prd"
        ).all()
        
        assert saved_meeting is not None
        assert saved_prd is not None
        assert len(saved_tasks) == 2
        assert saved_prd.reunion_id == "test-meeting"
```

---

## 6. Documentaci√≥n y Mejores Pr√°cticas

### 6.1. Code Documentation Standards

```python
from typing import Protocol, List, Optional, Dict, Any
from dataclasses import dataclass
from enum import Enum

class ProcessingResult:
    """
    ‚úÖ DOCUMENTATION - Resultado del procesamiento de una reuni√≥n.
    
    Esta clase encapsula el resultado completo del procesamiento de una reuni√≥n,
    incluyendo el PRD generado, las tareas asignadas y m√©tricas de rendimiento.
    
    Attributes:
        success (bool): Indica si el procesamiento fue exitoso
        prd (PRD): Documento de requisitos de producto generado
        tasks (List[TareaAsignada]): Lista de tareas asignadas por rol
        processing_time_seconds (float): Tiempo total de procesamiento
        error_message (Optional[str]): Mensaje de error si el procesamiento fall√≥
        
    Example:
        ```python
        result = ProcessingResult(
            success=True,
            prd=generated_prd,
            tasks=[task1, task2],
            processing_time_seconds=45.2
        )
        
        if result.success and result.meets_performance_requirement():
            notify_pm(result)
        ```
    """
    
    def __init__(
        self,
        success: bool,
        prd: Optional['PRD'] = None,
        tasks: Optional[List['TareaAsignada']] = None,
        processing_time_seconds: float = 0.0,
        error_message: Optional[str] = None
    ):
        self.success = success
        self.prd = prd
        self.tasks = tasks or []
        self.processing_time_seconds = processing_time_seconds
        self.error_message = error_message
    
    def meets_performance_requirement(self) -> bool:
        """
        ‚úÖ DOCUMENTATION - Verifica si cumple RNF1.0 (< 5 minutos).
        
        Returns:
            bool: True si el procesamiento tom√≥ menos de 5 minutos (300 segundos)
            
        Note:
            Este m√©todo implementa la verificaci√≥n del requisito no funcional
            RNF1.0 que especifica que el procesamiento debe completarse en
            menos de 5 minutos despu√©s de finalizar la reuni√≥n.
        """
        return self.processing_time_seconds < 300
    
    def get_performance_metrics(self) -> Dict[str, Any]:
        """
        ‚úÖ DOCUMENTATION - Obtiene m√©tricas de rendimiento del procesamiento.
        
        Returns:
            Dict[str, Any]: Diccionario con m√©tricas de rendimiento:
                - processing_time_seconds: Tiempo total de procesamiento
                - tasks_created_count: N√∫mero de tareas creadas
                - meets_sla: Si cumple con el SLA de 5 minutos
                - efficiency_score: Puntuaci√≥n de eficiencia (tasks/minute)
        """
        return {
            'processing_time_seconds': self.processing_time_seconds,
            'tasks_created_count': len(self.tasks),
            'meets_sla': self.meets_performance_requirement(),
            'efficiency_score': len(self.tasks) / max(self.processing_time_seconds / 60, 0.1)
        }
```

### 6.2. Configuration Management

```python
import os
from dataclasses import dataclass
from typing import Optional
import yaml

@dataclass
class ApplicationConfig:
    """
    ‚úÖ CONFIGURATION - Configuraci√≥n centralizada de la aplicaci√≥n.
    
    Maneja toda la configuraci√≥n de la aplicaci√≥n siguiendo el principio
    de "Configuration as Code" y separando la configuraci√≥n del c√≥digo.
    """
    
    # Database Configuration
    database_url: str
    redis_url: str
    mongodb_url: Optional[str] = None
    
    # External API Configuration  
    deepgram_api_key: str
    openai_api_key: str
    jira_api_token: str
    trello_api_key: str
    linear_api_key: str
    
    # Performance Configuration (RNF1.0)
    max_processing_time_seconds: int = 300  # 5 minutes
    transcription_timeout_seconds: int = 120
    max_retry_attempts: int = 3
    retry_backoff_base_seconds: int = 2
    
    # Security Configuration (RNF2.0)
    secret_manager_type: str = "aws"  # aws, azure, hashicorp
    encryption_key: str = ""
    api_rate_limit_per_minute: int = 100
    
    # Feature Flags
    enable_mongodb_storage: bool = False
    enable_advanced_nlp: bool = True
    enable_slack_notifications: bool = False
    
    @classmethod
    def from_environment(cls) -> 'ApplicationConfig':
        """
        ‚úÖ CONFIGURATION - Carga configuraci√≥n desde variables de entorno.
        
        Esta funci√≥n implementa el patr√≥n "12-Factor App" para configuraci√≥n,
        permitiendo diferentes configuraciones por ambiente sin cambiar c√≥digo.
        
        Returns:
            ApplicationConfig: Instancia configurada desde variables de entorno
            
        Raises:
            ConfigurationException: Si faltan variables de entorno requeridas
        """
        required_vars = [
            'DATABASE_URL', 'REDIS_URL', 'DEEPGRAM_API_KEY', 
            'OPENAI_API_KEY', 'JIRA_API_TOKEN'
        ]
        
        missing_vars = [var for var in required_vars if not os.getenv(var)]
        if missing_vars:
            raise ConfigurationException(f"Missing required environment variables: {missing_vars}")
        
        return cls(
            database_url=os.getenv('DATABASE_URL'),
            redis_url=os.getenv('REDIS_URL'),
            mongodb_url=os.getenv('MONGODB_URL'),
            deepgram_api_key=os.getenv('DEEPGRAM_API_KEY'),
            openai_api_key=os.getenv('OPENAI_API_KEY'),
            jira_api_token=os.getenv('JIRA_API_TOKEN'),
            trello_api_key=os.getenv('TRELLO_API_KEY', ''),
            linear_api_key=os.getenv('LINEAR_API_KEY', ''),
            max_processing_time_seconds=int(os.getenv('MAX_PROCESSING_TIME_SECONDS', '300')),
            secret_manager_type=os.getenv('SECRET_MANAGER_TYPE', 'aws'),
            enable_mongodb_storage=os.getenv('ENABLE_MONGODB_STORAGE', 'false').lower() == 'true',
            enable_advanced_nlp=os.getenv('ENABLE_ADVANCED_NLP', 'true').lower() == 'true'
        )
    
    @classmethod
    def from_yaml_file(cls, file_path: str) -> 'ApplicationConfig':
        """
        ‚úÖ CONFIGURATION - Carga configuraci√≥n desde archivo YAML.
        
        √ötil para desarrollo local y testing con configuraciones complejas.
        """
        with open(file_path, 'r') as file:
            config_data = yaml.safe_load(file)
        
        return cls(**config_data)
    
    def validate(self) -> None:
        """
        ‚úÖ CONFIGURATION - Valida la configuraci√≥n cargada.
        
        Verifica que la configuraci√≥n sea v√°lida y consistente antes de
        inicializar la aplicaci√≥n.
        
        Raises:
            ConfigurationException: Si la configuraci√≥n es inv√°lida
        """
        if self.max_processing_time_seconds < 60:
            raise ConfigurationException("Max processing time must be at least 60 seconds")
        
        if self.max_retry_attempts > 5:
            raise ConfigurationException("Max retry attempts should not exceed 5")
        
        if not self.database_url.startswith(('postgresql://', 'sqlite://')):
            raise ConfigurationException("Database URL must be PostgreSQL or SQLite")

# ‚úÖ CONFIGURATION - Singleton para configuraci√≥n global
class ConfigManager:
    _instance: Optional[ApplicationConfig] = None
    
    @classmethod
    def get_config(cls) -> ApplicationConfig:
        """Obtiene la configuraci√≥n global de la aplicaci√≥n (Singleton)."""
        if cls._instance is None:
            cls._instance = ApplicationConfig.from_environment()
            cls._instance.validate()
        return cls._instance
    
    @classmethod
    def set_config(cls, config: ApplicationConfig) -> None:
        """Establece la configuraci√≥n global (√∫til para testing)."""
        config.validate()
        cls._instance = config
```

---

## 7. Implementaci√≥n de Monitoreo y Alertas

### 7.1. Health Checks y Monitoring

```python
from enum import Enum
from dataclasses import dataclass
from typing import Dict, Any, List
import asyncio
import aiohttp
from datetime import datetime, timedelta

class HealthStatus(Enum):
    HEALTHY = "healthy"
    DEGRADED = "degraded"  
    UNHEALTHY = "unhealthy"

@dataclass
class ComponentHealth:
    """‚úÖ MONITORING - Estado de salud de un componente."""
    component_name: str
    status: HealthStatus
    response_time_ms: float
    error_message: Optional[str] = None
    last_check: datetime = datetime.utcnow()

class SystemHealthChecker:
    """
    ‚úÖ MONITORING - Monitor de salud del sistema completo.
    
    Implementa health checks para todos los componentes cr√≠ticos del sistema
    y proporciona una vista consolidada del estado de la aplicaci√≥n.
    """
    
    def __init__(self, config: ApplicationConfig):
        self.config = config
        self.health_history: List[ComponentHealth] = []
    
    async def check_system_health(self) -> Dict[str, Any]:
        """
        ‚úÖ MONITORING - Verifica la salud de todos los componentes.
        
        Returns:
            Dict con el estado de salud completo del sistema
        """
        checks = await asyncio.gather(
            self._check_database_health(),
            self._check_redis_health(),
            self._check_deepgram_health(),
            self._check_external_apis_health(),
            return_exceptions=True
        )
        
        component_healths = [check for check in checks if isinstance(check, ComponentHealth)]
        overall_status = self._determine_overall_health(component_healths)
        
        health_report = {
            'overall_status': overall_status.value,
            'timestamp': datetime.utcnow().isoformat(),
            'components': {health.component_name: {
                'status': health.status.value,
                'response_time_ms': health.response_time_ms,
                'error_message': health.error_message
            } for health in component_healths},
            'system_metrics': await self._get_system_metrics()
        }
        
        return health_report
    
    async def _check_database_health(self) -> ComponentHealth:
        """‚úÖ MONITORING - Verifica conectividad y rendimiento de BD."""
        start_time = time.time()
        
        try:
            # Simple query para verificar conectividad
            with self.db_manager.transaction() as session:
                result = session.execute(text("SELECT 1")).scalar()
                
            response_time = (time.time() - start_time) * 1000
            
            if response_time > 1000:  # > 1 segundo
                return ComponentHealth(
                    component_name="database",
                    status=HealthStatus.DEGRADED,
                    response_time_ms=response_time,
                    error_message="Database response time is slow"
                )
            
            return ComponentHealth(
                component_name="database",
                status=HealthStatus.HEALTHY,
                response_time_ms=response_time
            )
            
        except Exception as e:
            return ComponentHealth(
                component_name="database",
                status=HealthStatus.UNHEALTHY,
                response_time_ms=(time.time() - start_time) * 1000,
                error_message=str(e)
            )
    
    async def _check_deepgram_health(self) -> ComponentHealth:
        """‚úÖ MONITORING - Verifica disponibilidad de servicio de transcripci√≥n."""
        start_time = time.time()
        
        try:
            async with aiohttp.ClientSession() as session:
                async with session.get(
                    'https://api.deepgram.com/v1/projects',
                    headers={'Authorization': f'Token {self.config.deepgram_api_key}'},
                    timeout=aiohttp.ClientTimeout(total=10)
                ) as response:
                    
                    response_time = (time.time() - start_time) * 1000
                    
                    if response.status == 200:
                        return ComponentHealth(
                            component_name="deepgram",
                            status=HealthStatus.HEALTHY,
                            response_time_ms=response_time
                        )
                    else:
                        return ComponentHealth(
                            component_name="deepgram",
                            status=HealthStatus.UNHEALTHY,
                            response_time_ms=response_time,
                            error_message=f"HTTP {response.status}"
                        )
                        
        except Exception as e:
            return ComponentHealth(
                component_name="deepgram",
                status=HealthStatus.UNHEALTHY,
                response_time_ms=(time.time() - start_time) * 1000,
                error_message=str(e)
            )
    
    def _determine_overall_health(self, component_healths: List[ComponentHealth]) -> HealthStatus:
        """‚úÖ MONITORING - Determina el estado general del sistema."""
        if not component_healths:
            return HealthStatus.UNHEALTHY
        
        unhealthy_components = [h for h in component_healths if h.status == HealthStatus.UNHEALTHY]
        if unhealthy_components:
            return HealthStatus.UNHEALTHY
        
        degraded_components = [h for h in component_healths if h.status == HealthStatus.DEGRADED]
        if degraded_components:
            return HealthStatus.DEGRADED
        
        return HealthStatus.HEALTHY
    
    async def _get_system_metrics(self) -> Dict[str, Any]:
        """‚úÖ MONITORING - Obtiene m√©tricas del sistema."""
        return {
            'uptime_seconds': self._get_uptime_seconds(),
            'memory_usage_mb': self._get_memory_usage(),
            'active_processing_jobs': await self._get_active_jobs_count(),
            'average_response_time_ms': self._calculate_average_response_time(),
            'error_rate_percentage': self._calculate_error_rate()
        }
```

### 7.2. Alerting System

```python
from abc import ABC, abstractmethod
from typing import List, Dict, Any
from enum import Enum

class AlertSeverity(Enum):
    LOW = "low"
    MEDIUM = "medium"
    HIGH = "high"
    CRITICAL = "critical"

@dataclass
class Alert:
    """‚úÖ ALERTING - Estructura de una alerta."""
    id: str
    severity: AlertSeverity
    component: str
    message: str
    timestamp: datetime
    resolved: bool = False
    metadata: Dict[str, Any] = None

class AlertingRule:
    """‚úÖ ALERTING - Regla de alertas configurable."""
    
    def __init__(
        self,
        name: str,
        condition: Callable[[Dict[str, Any]], bool],
        severity: AlertSeverity,
        message_template: str,
        cooldown_minutes: int = 15
    ):
        self.name = name
        self.condition = condition
        self.severity = severity
        self.message_template = message_template
        self.cooldown_minutes = cooldown_minutes
        self.last_triggered = None

class AlertManager:
    """
    ‚úÖ ALERTING - Gestor de alertas del sistema.
    
    Eval√∫a reglas de alertas, env√≠a notificaciones y gestiona el ciclo
    de vida de las alertas del sistema.
    """
    
    def __init__(self, notification_services: List['NotificationService']):
        self.notification_services = notification_services
        self.active_alerts: Dict[str, Alert] = {}
        self.alerting_rules = self._setup_default_rules()
    
    def _setup_default_rules(self) -> List[AlertingRule]:
        """‚úÖ ALERTING - Configuraci√≥n de reglas por defecto."""
        return [
            # RNF1.0 - Performance Alert
            AlertingRule(
                name="processing_time_exceeded",
                condition=lambda metrics: metrics.get('average_response_time_ms', 0) > 300000,  # 5 min
                severity=AlertSeverity.HIGH,
                message_template="Processing time exceeded 5 minutes: {average_response_time_ms}ms",
                cooldown_minutes=5
            ),
            
            # Database Health Alert
            AlertingRule(
                name="database_unhealthy",
                condition=lambda health: health.get('components', {}).get('database', {}).get('status') == 'unhealthy',
                severity=AlertSeverity.CRITICAL,
                message_template="Database is unhealthy: {error_message}",
                cooldown_minutes=1
            ),
            
            # External API Alert
            AlertingRule(
                name="deepgram_unavailable",
                condition=lambda health: health.get('components', {}).get('deepgram', {}).get('status') == 'unhealthy',
                severity=AlertSeverity.HIGH,
                message_template="Deepgram service is unavailable: {error_message}",
                cooldown_minutes=10
            ),
            
            # Error Rate Alert
            AlertingRule(
                name="high_error_rate",
                condition=lambda metrics: metrics.get('error_rate_percentage', 0) > 10,
                severity=AlertSeverity.MEDIUM,
                message_template="Error rate is high: {error_rate_percentage}%",
                cooldown_minutes=30
            )
        ]
    
    async def evaluate_alerts(self, health_report: Dict[str, Any]) -> List[Alert]:
        """
        ‚úÖ ALERTING - Eval√∫a todas las reglas de alertas.
        
        Args:
            health_report: Reporte de salud del sistema
            
        Returns:
            Lista de alertas nuevas generadas
        """
        new_alerts = []
        
        for rule in self.alerting_rules:
            if self._should_evaluate_rule(rule) and rule.condition(health_report):
                alert = self._create_alert_from_rule(rule, health_report)
                new_alerts.append(alert)
                self.active_alerts[alert.id] = alert
                
                # Enviar notificaciones
                await self._send_alert_notifications(alert)
        
        return new_alerts
    
    def _should_evaluate_rule(self, rule: AlertingRule) -> bool:
        """‚úÖ ALERTING - Verifica si debe evaluar la regla (cooldown)."""
        if rule.last_triggered is None:
            return True
        
        cooldown_threshold = datetime.utcnow() - timedelta(minutes=rule.cooldown_minutes)
        return rule.last_triggered < cooldown_threshold
    
    def _create_alert_from_rule(self, rule: AlertingRule, context: Dict[str, Any]) -> Alert:
        """‚úÖ ALERTING - Crea alerta a partir de regla y contexto."""
        import uuid
        
        alert_id = f"{rule.name}-{uuid.uuid4().hex[:8]}"
        message = rule.message_template.format(**context.get('system_metrics', {}))
        
        rule.last_triggered = datetime.utcnow()
        
        return Alert(
            id=alert_id,
            severity=rule.severity,
            component=rule.name,
            message=message,
            timestamp=datetime.utcnow(),
            metadata=context
        )
    
    async def _send_alert_notifications(self, alert: Alert) -> None:
        """‚úÖ ALERTING - Env√≠a notificaciones de alerta."""
        for service in self.notification_services:
            try:
                await service.send_alert_notification(alert)
            except Exception as e:
                # Log error pero no fallar por notificaciones
                logger.error(f"Failed to send alert notification via {service.__class__.__name__}: {e}")

class SlackAlertNotificationService:
    """‚úÖ ALERTING - Servicio de notificaciones por Slack."""
    
    def __init__(self, webhook_url: str, channel: str = "#alerts"):
        self.webhook_url = webhook_url
        self.channel = channel
    
    async def send_alert_notification(self, alert: Alert) -> None:
        """Env√≠a alerta a canal de Slack."""
        
        color_map = {
            AlertSeverity.LOW: "good",
            AlertSeverity.MEDIUM: "warning", 
            AlertSeverity.HIGH: "danger",
            AlertSeverity.CRITICAL: "danger"
        }
        
        payload = {
            "channel": self.channel,
            "username": "M2PRD Alert Bot",
            "icon_emoji": ":rotating_light:",
            "attachments": [{
                "color": color_map.get(alert.severity, "warning"),
                "title": f"{alert.severity.value.upper()} Alert: {alert.component}",
                "text": alert.message,
                "timestamp": alert.timestamp.timestamp(),
                "fields": [
                    {"title": "Component", "value": alert.component, "short": True},
                    {"title": "Severity", "value": alert.severity.value, "short": True}
                ]
            }]
        }
        
        async with aiohttp.ClientSession() as session:
            async with session.post(self.webhook_url, json=payload) as response:
                if response.status != 200:
                    raise Exception(f"Slack notification failed: {response.status}")
```

---

## 8. Deployment y DevOps Practices

### 8.1. Infrastructure as Code

```yaml
# ‚úÖ DEVOPS - docker-compose.yml para desarrollo local
version: '3.8'

services:
  # PostgreSQL para metadata y auditor√≠a (ACID compliance)
  postgres:
    image: postgres:15-alpine
    environment:
      POSTGRES_DB: m2prd_db
      POSTGRES_USER: m2prd_user
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD}
    ports:
      - "5432:5432"
    volumes:
      - postgres_data:/var/lib/postgresql/data
      - ./sql/init.sql:/docker-entrypoint-initdb.d/init.sql
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U m2prd_user -d m2prd_db"]
      interval: 30s
      timeout: 10s
      retries: 5

  # Redis para cach√© y gesti√≥n de tokens (RNF2.0)
  redis:
    image: redis:7-alpine
    ports:
      - "6379:6379"
    command: redis-server --appendonly yes --requirepass ${REDIS_PASSWORD}
    volumes:
      - redis_data:/data
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 30s
      timeout: 10s
      retries: 3

  # n8n para orquestaci√≥n (Requirement PRD)
  n8n:
    image: n8nio/n8n:latest
    ports:
      - "5678:5678"
    environment:
      - DB_TYPE=postgresdb
      - DB_POSTGRESDB_HOST=postgres
      - DB_POSTGRESDB_PORT=5432
      - DB_POSTGRESDB_DATABASE=n8n_db
      - DB_POSTGRESDB_USER=n8n_user
      - DB_POSTGRESDB_PASSWORD=${N8N_POSTGRES_PASSWORD}
      - N8N_BASIC_AUTH_ACTIVE=true
      - N8N_BASIC_AUTH_USER=${N8N_BASIC_AUTH_USER}
      - N8N_BASIC_AUTH_PASSWORD=${N8N_BASIC_AUTH_PASSWORD}
      - WEBHOOK_URL=http://localhost:5678
    volumes:
      - n8n_data:/home/node/.n8n
      - ./n8n/workflows:/home/node/.n8n/workflows
    depends_on:
      postgres:
        condition: service_healthy
      redis:
        condition: service_healthy

  # Python AI/NLP Service (Serverless locally with container)
  nlp-service:
    build:
      context: ./services/nlp
      dockerfile: Dockerfile
    ports:
      - "8000:8000"
    environment:
      - DATABASE_URL=postgresql://m2prd_user:${POSTGRES_PASSWORD}@postgres:5432/m2prd_db
      - REDIS_URL=redis://default:${REDIS_PASSWORD}@redis:6379
      - DEEPGRAM_API_KEY=${DEEPGRAM_API_KEY}
      - OPENAI_API_KEY=${OPENAI_API_KEY}
      - LOG_LEVEL=INFO
    volumes:
      - ./services/nlp:/app
    depends_on:
      postgres:
        condition: service_healthy
      redis:
        condition: service_healthy
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/health"]
      interval: 30s
      timeout: 10s
      retries: 3

  # Monitoring con Prometheus
  prometheus:
    image: prom/prometheus:latest
    ports:
      - "9090:9090"
    volumes:
      - ./monitoring/prometheus.yml:/etc/prometheus/prometheus.yml
      - prometheus_data:/prometheus
    command:
      - '--config.file=/etc/prometheus/prometheus.yml'
      - '--storage.tsdb.path=/prometheus'
      - '--web.console.libraries=/etc/prometheus/console_libraries'
      - '--web.console.templates=/etc/prometheus/consoles'

volumes:
  postgres_data:
  redis_data:
  n8n_data:
  prometheus_data:
```

### 8.2. CI/CD Pipeline

```yaml
# ‚úÖ DEVOPS - .github/workflows/ci-cd.yml
name: M2PRD-001 CI/CD Pipeline

on:
  push:
    branches: [main, develop]
  pull_request:
    branches: [main]

env:
  PYTHON_VERSION: "3.11"
  NODE_VERSION: "18"

jobs:
  # ‚úÖ QUALITY ASSURANCE - Linting y an√°lisis est√°tico
  lint-and-format:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
      
      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: ${{ env.PYTHON_VERSION }}
      
      - name: Install Python dependencies
        run: |
          pip install black isort flake8 mypy pytest-cov
          pip install -r requirements.txt
      
      - name: Format code with Black
        run: black --check --diff services/nlp/
      
      - name: Sort imports with isort
        run: isort --check-only --diff services/nlp/
      
      - name: Lint with flake8
        run: |
          flake8 services/nlp/ --count --select=E9,F63,F7,F82 --show-source --statistics
          flake8 services/nlp/ --count --exit-zero --max-complexity=10 --max-line-length=127 --statistics
      
      - name: Type check with mypy
        run: mypy services/nlp/ --strict

  # ‚úÖ TESTING - Suite completa de tests
  test:
    runs-on: ubuntu-latest
    needs: lint-and-format
    
    services:
      postgres:
        image: postgres:15
        env:
          POSTGRES_PASSWORD: test_password
          POSTGRES_USER: test_user
          POSTGRES_DB: test_db
        options: >-
          --health-cmd pg_isready
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5
        ports:
          - 5432:5432
      
      redis:
        image: redis:7
        options: >-
          --health-cmd "redis-cli ping"
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5
        ports:
          - 6379:6379

    steps:
      - uses: actions/checkout@v4
      
      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: ${{ env.PYTHON_VERSION }}
      
      - name: Install dependencies
        run: |
          pip install -r requirements.txt
          pip install -r requirements-test.txt
      
      - name: Run unit tests
        env:
          DATABASE_URL: postgresql://test_user:test_password@localhost:5432/test_db
          REDIS_URL: redis://localhost:6379
        run: |
          pytest tests/unit/ -v --cov=services/nlp --cov-report=xml --cov-report=html
      
      - name: Run integration tests  
        env:
          DATABASE_URL: postgresql://test_user:test_password@localhost:5432/test_db
          REDIS_URL: redis://localhost:6379
        run: |
          pytest tests/integration/ -v --cov-append --cov=services/nlp --cov-report=xml
      
      - name: Upload coverage to Codecov
        uses: codecov/codecov-action@v3
        with:
          file: ./coverage.xml
          fail_ci_if_error: true

  # ‚úÖ SECURITY - An√°lisis de vulnerabilidades
  security-scan:
    runs-on: ubuntu-latest
    needs: lint-and-format
    
    steps:
      - uses: actions/checkout@v4
      
      - name: Run security scan with Bandit
        run: |
          pip install bandit[toml]
          bandit -r services/nlp/ -f json -o bandit-report.json
      
      - name: Run dependency vulnerability check
        run: |
          pip install safety
          safety check --json --output safety-report.json
      
      - name: Upload security reports
        uses: actions/upload-artifact@v3
        with:
          name: security-reports
          path: |
            bandit-report.json
            safety-report.json

  # ‚úÖ PERFORMANCE - Tests de rendimiento (RNF1.0)
  performance-test:
    runs-on: ubuntu-latest
    needs: test
    if: github.ref == 'refs/heads/main'
    
    steps:
      - uses: actions/checkout@v4
      
      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: ${{ env.PYTHON_VERSION }}
      
      - name: Install performance testing dependencies
        run: |
          pip install -r requirements.txt
          pip install locust pytest-benchmark
      
      - name: Run performance benchmarks
        run: |
          pytest tests/performance/ --benchmark-only --benchmark-json=benchmark.json
      
      - name: Validate RNF1.0 (< 5 minutes processing time)
        run: |
          python scripts/validate_performance_requirements.py --benchmark-file=benchmark.json

  # ‚úÖ DEPLOYMENT - Deploy to staging/production
  deploy:
    runs-on: ubuntu-latest
    needs: [test, security-scan, performance-test]
    if: github.ref == 'refs/heads/main'
    
    steps:
      - uses: actions/checkout@v4
      
      - name: Configure AWS credentials
        uses: aws-actions/configure-aws-credentials@v2
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: us-east-1
      
      - name: Build and push Docker image
        run: |
          docker build -t m2prd-nlp-service:${{ github.sha }} services/nlp/
          docker tag m2prd-nlp-service:${{ github.sha }} ${{ secrets.ECR_REGISTRY }}/m2prd-nlp-service:${{ github.sha }}
          docker tag m2prd-nlp-service:${{ github.sha }} ${{ secrets.ECR_REGISTRY }}/m2prd-nlp-service:latest
          docker push ${{ secrets.ECR_REGISTRY }}/m2prd-nlp-service:${{ github.sha }}
          docker push ${{ secrets.ECR_REGISTRY }}/m2prd-nlp-service:latest
      
      - name: Deploy to AWS Lambda (Serverless)
        run: |
          # Deploy Python NLP service as Lambda function
          aws lambda update-function-code \
            --function-name m2prd-nlp-processor \
            --image-uri ${{ secrets.ECR_REGISTRY }}/m2prd-nlp-service:${{ github.sha }}
      
      - name: Update Lambda environment variables
        run: |
          aws lambda update-function-configuration \
            --function-name m2prd-nlp-processor \
            --environment Variables="{
              DATABASE_URL=${{ secrets.PROD_DATABASE_URL }},
              REDIS_URL=${{ secrets.PROD_REDIS_URL }},
              DEEPGRAM_API_KEY=${{ secrets.DEEPGRAM_API_KEY }},
              OPENAI_API_KEY=${{ secrets.OPENAI_API_KEY }}
            }"
      
      - name: Run post-deployment health checks
        run: |
          python scripts/health_check.py --environment=production --timeout=300
      
      - name: Notify deployment success
        uses: 8398a7/action-slack@v3
        with:
          status: success
          channel: '#deployments'
          text: "‚úÖ M2PRD-001 deployed successfully to production"
        env:
          SLACK_WEBHOOK_URL: ${{ secrets.SLACK_WEBHOOK_URL }}
```

---

## 9. Resumen de Implementaci√≥n

### 9.1. Checklist de Principios Aplicados

| Principio/Patr√≥n | ‚úÖ Implementado | Descripci√≥n de Aplicaci√≥n |
|------------------|----------------|---------------------------|
| **SRP (Single Responsibility)** | ‚úÖ | Cada clase tiene una responsabilidad √∫nica (AudioCaptureService, TranscriptionService, etc.) |
| **OCP (Open/Closed)** | ‚úÖ | Extensible v√≠a PMSIntegrationFactory sin modificar c√≥digo existente |
| **LSP (Liskov Substitution)** | ‚úÖ | Jerarqu√≠a de Requisito permite sustituci√≥n sin romper comportamiento |
| **ISP (Interface Segregation)** | ‚úÖ | Interfaces espec√≠ficas (AudioProcessable, TextAnalyzable, etc.) |
| **DIP (Dependency Inversion)** | ‚úÖ | Dependencias por abstracci√≥n con inversi√≥n de control |
| **KISS Principle** | ‚úÖ | Implementaciones directas sin complejidad innecesaria |
| **Clean Architecture** | ‚úÖ | Capas bien definidas con dependencias hacia adentro |
| **Factory Pattern** | ‚úÖ | RoleAssignmentFactory para RF4.0 - Asignaci√≥n Inteligente |
| **Strategy Pattern** | ‚úÖ | M√∫ltiples algoritmos de NLP intercambiables |
| **Observer Pattern** | ‚úÖ | Sistema de notificaciones para alertas del PM |
| **Circuit Breaker** | ‚úÖ | Protecci√≥n para RNF5.0 - Tolerancia a Fallos |
| **ACID Principles** | ‚úÖ | Transacciones at√≥micas con PostgreSQL |
| **Ports & Adapters** | ‚úÖ | Abstracciones para servicios externos (Deepgram, APIs PMS) |

### 9.2. Mapeo a Requisitos del Proyecto

| Requisito | Principio/Patr√≥n Aplicado | Implementaci√≥n |
|-----------|---------------------------|----------------|
| **RF4.0 - Asignaci√≥n Inteligente** | Factory Pattern + Strategy Pattern | RoleAssignmentFactory con clasificadores intercambiables |
| **RF5.0 - Integraci√≥n PMS** | Open/Closed + Factory Pattern | PMSIntegrationFactory extensible (Jira, Trello, Linear) |
| **RNF1.0 - Rendimiento < 5min** | Circuit Breaker + Monitoring | Health checks y alertas de rendimiento |
| **RNF2.0 - Seguridad** | Configuration Management + DIP | Gestores de secretos externos por inversi√≥n de dependencias |
| **RNF5.0 - Tolerancia a Fallos** | Circuit Breaker + Retry Pattern | Reintentos exponenciales con circuit breaker |

---

## ‚ö†Ô∏è Advertencias Cr√≠ticas sobre Implementaci√≥n

### Revisi√≥n Humana Obligatoria

**IMPORTANTE**: Este documento contiene arquitecturas y patrones de dise√±o generados con asistencia de IA. Antes de implementar cualquier parte de esta arquitectura:

1. **Revisi√≥n de Arquitectura**: Un arquitecto de software senior debe revisar y validar todas las decisiones arquitect√≥nicas propuestas.

2. **Validaci√≥n de Patrones**: Los patrones de dise√±o deben ser evaluados en el contexto espec√≠fico del proyecto para confirmar su aplicabilidad.

3. **Testing Exhaustivo**: Todos los componentes cr√≠ticos requieren pruebas unitarias, de integraci√≥n y de carga antes del despliegue.

4. **Revisi√≥n de Seguridad**: Un especialista en seguridad debe validar las implementaciones de RNF2.0 (gesti√≥n de credenciales y tokens).

5. **Validaci√≥n de Rendimiento**: Los requisitos de RNF1.0 (< 5 minutos) deben ser validados con datos reales en entorno similar a producci√≥n.

### Limitaciones de LLMs

- **Alucinaciones**: El c√≥digo y arquitecturas generadas pueden contener errores sutiles que parecen correctos
- **Contexto Limitado**: Algunos detalles espec√≠ficos del proyecto pueden no haber sido considerados completamente
- **Evoluci√≥n Tecnol√≥gica**: Las mejores pr√°cticas y bibliotecas recomendadas deben ser validadas con versiones actuales

### Proceso de Implementaci√≥n Recomendado

1. **Fase 1**: Implementar MVP con arquitectura simplificada
2. **Fase 2**: Validar patrones con m√©tricas reales 
3. **Fase 3**: Refactorizar aplicando principios avanzados gradualmente
4. **Fase 4**: Optimizaci√≥n basada en datos de producci√≥n

**La implementaci√≥n exitosa de estos principios requiere experiencia humana, juicio t√©cnico y validaci√≥n continua con m√©tricas reales del sistema.**