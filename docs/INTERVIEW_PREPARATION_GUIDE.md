# ğŸ¯ GuÃ­a de PreparaciÃ³n para Entrevista TÃ©cnica - M2PRD-001 SaaS

## ğŸ“‹ Ãndice

1. [VisiÃ³n General del Sistema](#1-visiÃ³n-general-del-sistema)
2. [Arquitectura del Sistema](#2-arquitectura-del-sistema)
3. [Decisiones de DiseÃ±o Clave](#3-decisiones-de-diseÃ±o-clave)
4. [Stack TecnolÃ³gico y JustificaciÃ³n](#4-stack-tecnolÃ³gico-y-justificaciÃ³n)
5. [Principios de Arquitectura Aplicados](#5-principios-de-arquitectura-aplicados)
6. [Patrones de DiseÃ±o Implementados](#6-patrones-de-diseÃ±o-implementados)
7. [GestiÃ³n de Bases de Datos y ACID](#7-gestiÃ³n-de-bases-de-datos-y-acid)
8. [Seguridad y GestiÃ³n de Secretos](#8-seguridad-y-gestiÃ³n-de-secretos)
9. [Testing y Calidad de CÃ³digo](#9-testing-y-calidad-de-cÃ³digo)
10. [DockerizaciÃ³n y DevOps](#10-dockerizaciÃ³n-y-devops)
11. [Posibles Mejoras y Roadmap](#11-posibles-mejoras-y-roadmap)
12. [Preguntas Frecuentes en Entrevistas](#12-preguntas-frecuentes-en-entrevistas)

---

## 1. VisiÃ³n General del Sistema

### Â¿QuÃ© es M2PRD-001?

**M2PRD-001** (Meet-to-PRD) es un **sistema SaaS de monetizaciÃ³n** que forma parte de un proyecto mÃ¡s grande de transformaciÃ³n automÃ¡tica de reuniones en documentos PRD (Product Requirements Documents).

**Tu Componente EspecÃ­fico: Gatekeeper Service (RF8.0)**

Eres responsable del **servicio crÃ­tico de control de consumo y monetizaciÃ³n**, que actÃºa como **gatekeeper** verificando que los usuarios tengan horas disponibles antes de procesar reuniones.

### Flujo de Alto Nivel

```
1. Usuario solicita procesar reuniÃ³n
2. âœ… GATEKEEPER verifica horas disponibles (TU COMPONENTE)
3. Si OK â†’ Trigger n8n workflow
4. n8n procesa (transcripciÃ³n, IA/NLP)
5. Callback â†’ GATEKEEPER actualiza consumo
6. Usuario recibe PRD y tareas
```

### Caso de Uso Real

```
ğŸ‘¤ Usuario (Plan BÃ¡sico: 10 horas/mes)
   - Ha consumido 7 horas
   - Disponibles: 3 horas

ğŸ“¹ Quiere procesar reuniÃ³n de 2 horas
   âœ… Gatekeeper: OK (3 - 2 = 1 hora restante)
   â†’ Procesa reuniÃ³n
   â†’ Actualiza: Disponibles = 1 hora

ğŸ“¹ Intenta procesar otra de 2 horas
   âŒ Gatekeeper: RECHAZADO (solo 1 hora disponible)
   â†’ Redirige a upgrade de plan
```

---

## 2. Arquitectura del Sistema

### 2.1. Arquitectura de Capas (Clean Architecture)

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   API LAYER (FastAPI)                       â”‚
â”‚  â€¢ Endpoints REST                                           â”‚
â”‚  â€¢ ValidaciÃ³n con Pydantic                                  â”‚
â”‚  â€¢ Swagger/OpenAPI docs                                     â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                 APPLICATION LAYER                           â”‚
â”‚  â€¢ Use Cases (ProcessMeetingUseCase)                        â”‚
â”‚  â€¢ Business Rules Orchestration                             â”‚
â”‚  â€¢ DTOs y Request/Response Models                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                   DOMAIN LAYER                              â”‚
â”‚  â€¢ Entities (User, Subscription, UsageLog)                  â”‚
â”‚  â€¢ Value Objects                                            â”‚
â”‚  â€¢ Domain Services                                          â”‚
â”‚  â€¢ Business Logic                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚               INFRASTRUCTURE LAYER                          â”‚
â”‚  â€¢ Database (PostgreSQL + SQLAlchemy)                       â”‚
â”‚  â€¢ Cache (Redis)                                            â”‚
â”‚  â€¢ External APIs (n8n, Stripe)                              â”‚
â”‚  â€¢ Configuration Management                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**JustificaciÃ³n**: Clean Architecture permite **testabilidad**, **mantenibilidad** y **escalabilidad**. La lÃ³gica de negocio no depende de frameworks o bases de datos especÃ­ficas.

### 2.2. Diagrama de Flujo Principal

```mermaid
sequenceDiagram
    participant User as Usuario/API
    participant API as FastAPI Router
    participant UC as Use Case
    participant DB as PostgreSQL
    participant Redis as Redis Cache
    participant n8n as n8n Workflow

    User->>API: POST /api/v1/consumption/verify
    API->>UC: verify_and_trigger_processing()
    
    UC->>Redis: Check cache (lÃ­mites)
    Redis-->>UC: Cache miss
    
    UC->>DB: BEGIN TRANSACTION
    UC->>DB: SELECT available_hours FOR UPDATE
    DB-->>UC: 3.0 horas disponibles
    
    alt Horas Suficientes
        UC->>DB: Reserve estimated_hours
        UC->>DB: COMMIT
        UC->>n8n: Trigger webhook (meeting_data)
        n8n-->>UC: 202 Accepted
        UC->>Redis: Update cache
        UC-->>API: 200 OK (processing_started)
        API-->>User: Success response
    else Horas Insuficientes
        UC->>DB: ROLLBACK
        UC-->>API: 402 Payment Required
        API-->>User: Error: Insufficient hours
    end
    
    Note over n8n: Procesamiento asÃ­ncrono (2-5 min)
    
    n8n->>API: POST /callback (results)
    API->>UC: update_consumption()
    UC->>DB: BEGIN TRANSACTION
    UC->>DB: UPDATE available_hours
    UC->>DB: INSERT usage_log
    UC->>DB: COMMIT
    UC->>Redis: Invalidate cache
```

### 2.3. Estructura de Directorios

```
backend/
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ main.py                      # FastAPI application
â”‚   â”œâ”€â”€ core/
â”‚   â”‚   â”œâ”€â”€ config.py                # âœ… ConfiguraciÃ³n centralizada
â”‚   â”‚   â”œâ”€â”€ database.py              # âœ… SQLAlchemy setup + ACID
â”‚   â”‚   â””â”€â”€ security.py              # âœ… JWT, hashing
â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â”œâ”€â”€ domain/                  # âœ… DOMAIN LAYER
â”‚   â”‚   â”‚   â”œâ”€â”€ user.py
â”‚   â”‚   â”‚   â”œâ”€â”€ subscription.py
â”‚   â”‚   â”‚   â””â”€â”€ usage_log.py
â”‚   â”‚   â””â”€â”€ schemas/                 # âœ… Pydantic DTOs
â”‚   â”‚       â”œâ”€â”€ consumption.py
â”‚   â”‚       â””â”€â”€ webhook.py
â”‚   â”œâ”€â”€ services/
â”‚   â”‚   â”œâ”€â”€ consumption_service.py   # âœ… Business Logic
â”‚   â”‚   â”œâ”€â”€ webhook_trigger.py       # âœ… n8n integration
â”‚   â”‚   â””â”€â”€ stripe_service.py        # âœ… Payments
â”‚   â”œâ”€â”€ repositories/
â”‚   â”‚   â”œâ”€â”€ subscription_repo.py     # âœ… Data Access Layer
â”‚   â”‚   â””â”€â”€ usage_log_repo.py
â”‚   â””â”€â”€ api/
â”‚       â””â”€â”€ v1/
â”‚           â””â”€â”€ consumption_router.py # âœ… REST API
â”œâ”€â”€ tests/
â”‚   â”œâ”€â”€ unit/                        # âœ… Unit tests
â”‚   â”œâ”€â”€ integration/                 # âœ… Integration tests
â”‚   â””â”€â”€ mocks/
â”‚       â””â”€â”€ mock_n8n_server.py       # âœ… Mock server for dev
â”œâ”€â”€ Dockerfile                       # âœ… Multi-stage build
â””â”€â”€ requirements.txt                 # âœ… Dependencies
```

---

## 3. Decisiones de DiseÃ±o Clave

### 3.1. Â¿Por quÃ© FastAPI?

**DecisiÃ³n**: Usar FastAPI en lugar de Django o Flask

**JustificaciÃ³n**:
1. **Performance**: ASGI asÃ­ncrono â†’ 3-5x mÃ¡s rÃ¡pido que Flask/Django
2. **Type Safety**: IntegraciÃ³n nativa con Pydantic para validaciÃ³n automÃ¡tica
3. **OpenAPI/Swagger**: DocumentaciÃ³n automÃ¡tica out-of-the-box
4. **Modern Python**: Usa async/await, type hints Python 3.11+
5. **Lightweight**: No tiene "batteries included" innecesarias de Django

**Trade-off Aceptado**: Menos "baterÃ­as incluidas" que Django, pero mÃ¡s flexible.

### 3.2. Â¿Por quÃ© PostgreSQL (no MongoDB)?

**DecisiÃ³n**: PostgreSQL para datos financieros crÃ­ticos

**JustificaciÃ³n**:
1. **ACID Compliance**: Transacciones atÃ³micas para facturaciÃ³n
2. **FOREIGN KEYS**: Integridad referencial garantizada
3. **TRANSACTIONS**: `BEGIN`, `COMMIT`, `ROLLBACK` para consistencia
4. **ROW-LEVEL LOCKING**: `SELECT ... FOR UPDATE` evita race conditions
5. **Mature Ecosystem**: Battle-tested para fintech

**Ejemplo CrÃ­tico**:
```python
# Esto DEBE ser atÃ³mico (todo o nada)
BEGIN TRANSACTION;
  UPDATE subscriptions SET available_hours = available_hours - 2.0;
  INSERT INTO usage_logs (hours_consumed, meeting_id);
COMMIT;  # Si falla â†’ ROLLBACK automÃ¡tico
```

### 3.3. Â¿Por quÃ© Redis como Cache?

**DecisiÃ³n**: Redis para cache de lÃ­mites de consumo

**JustificaciÃ³n**:
1. **Low Latency**: < 1ms response time vs 10-50ms PostgreSQL
2. **Reduce DB Load**: Menos queries al DB transaccional
3. **Session Store**: Puede usarse para JWT blacklist
4. **Rate Limiting**: Contadores atÃ³micos para throttling

**Cache Strategy (Write-Through)**:
```python
async def get_available_hours(user_id: str) -> float:
    # 1. Try cache first
    cached = await redis.get(f"hours:{user_id}")
    if cached:
        return float(cached)
    
    # 2. Cache miss â†’ Query DB
    hours = await db.query_available_hours(user_id)
    
    # 3. Update cache (TTL 5 min)
    await redis.setex(f"hours:{user_id}", 300, hours)
    
    return hours
```

### 3.4. Â¿Por quÃ© Separar en Microservicio?

**DecisiÃ³n**: Gatekeeper como servicio independiente

**JustificaciÃ³n**:
1. **Single Responsibility**: Solo maneja consumo/monetizaciÃ³n
2. **Escalado Independiente**: Puede escalar separado del resto
3. **Failure Isolation**: Si falla, no afecta otros servicios
4. **Team Ownership**: Un equipo dueÃ±o del servicio completo
5. **Technology Flexibility**: Puede cambiar stack sin afectar otros

**Trade-off**: MÃ¡s complejidad operacional (mÃºltiples servicios).

### 3.5. Â¿Por quÃ© Mock n8n Server?

**DecisiÃ³n**: Crear mock server para desarrollo local

**JustificaciÃ³n**:
1. **Development Speed**: No necesitas n8n corriendo localmente
2. **Testing**: Tests unitarios sin dependencias externas
3. **Deterministic Behavior**: Controlas exactamente las respuestas
4. **Fast Feedback Loop**: < 5 segundos vs minutos con n8n real

**ImplementaciÃ³n**:
```python
# tests/mocks/mock_n8n_server.py
@app.post("/webhook/process-meeting")
async def process_meeting(request: WebhookRequest):
    # Simula procesamiento
    await asyncio.sleep(random.uniform(2, 5))
    
    # Auto-callback al Gatekeeper
    await httpx.post(
        "http://gatekeeper:8002/api/v1/consumption/process/callback",
        json={"status": "success", "processing_time": 3.5}
    )
```

---

## 4. Stack TecnolÃ³gico y JustificaciÃ³n

### 4.1. Backend Stack

| TecnologÃ­a | VersiÃ³n | JustificaciÃ³n |
|------------|---------|---------------|
| **Python** | 3.11+ | Type hints, performance, async/await |
| **FastAPI** | 0.104.1 | Async, type-safe, auto docs |
| **Pydantic** | 2.5.0 | ValidaciÃ³n robusta, type safety |
| **SQLAlchemy** | 2.0.23 | ORM maduro, async support |
| **Alembic** | 1.13.0 | Migraciones de DB versionadas |
| **PostgreSQL** | 15 | ACID, transacciones, madurez |
| **Redis** | 7 | Cache, session store |
| **httpx** | 0.25.2 | Cliente HTTP async |
| **pytest** | latest | Testing framework estÃ¡ndar |

### 4.2. DevOps Stack

| TecnologÃ­a | JustificaciÃ³n |
|------------|---------------|
| **Docker** | Reproducibilidad, portabilidad |
| **Docker Compose** | OrquestaciÃ³n local simple |
| **Makefile** | Comandos simplificados (DX) |
| **GitHub Actions** | CI/CD (potencial) |
| **Prometheus** | MÃ©tricas (en docker-compose.yml) |
| **Grafana** | VisualizaciÃ³n mÃ©tricas |

### 4.3. Testing Stack

| Tipo | Herramienta | Coverage |
|------|-------------|----------|
| **Unit Tests** | pytest | 93.5% |
| **Integration Tests** | pytest + TestClient | Endpoints API |
| **Mocking** | unittest.mock | External services |
| **Fixtures** | pytest fixtures | Setup/teardown |

---

## 5. Principios de Arquitectura Aplicados

### 5.1. SOLID Principles

#### **S - Single Responsibility Principle**

**Ejemplo**: Cada servicio tiene una responsabilidad clara

```python
# âœ… BUENO: Cada clase tiene UNA responsabilidad
class ConsumptionService:
    """Solo maneja lÃ³gica de consumo"""
    
    def verify_available_hours(self, user_id: str, hours: float) -> bool:
        pass

class WebhookTrigger:
    """Solo maneja trigger de webhooks"""
    
    def trigger_n8n_workflow(self, meeting_data: dict) -> None:
        pass

class StripeService:
    """Solo maneja pagos con Stripe"""
    
    def create_subscription(self, user_id: str, plan_id: str) -> Subscription:
        pass
```

#### **O - Open/Closed Principle**

**Ejemplo**: Extensible sin modificar cÃ³digo existente

```python
# âœ… Abierto para extensiÃ³n, cerrado para modificaciÃ³n
class PaymentGateway(ABC):
    @abstractmethod
    def process_payment(self, amount: float) -> PaymentResult:
        pass

class StripeGateway(PaymentGateway):
    def process_payment(self, amount: float) -> PaymentResult:
        # ImplementaciÃ³n Stripe
        pass

class PayPalGateway(PaymentGateway):  # âœ… Nueva funcionalidad sin cambiar cÃ³digo
    def process_payment(self, amount: float) -> PaymentResult:
        # ImplementaciÃ³n PayPal
        pass
```

#### **L - Liskov Substitution Principle**

**Ejemplo**: Cualquier implementaciÃ³n de Repository puede usarse

```python
# âœ… Cualquier SubscriptionRepository es intercambiable
class SubscriptionRepository(ABC):
    @abstractmethod
    async def get_by_user_id(self, user_id: str) -> Subscription:
        pass

class PostgresSubscriptionRepository(SubscriptionRepository):
    async def get_by_user_id(self, user_id: str) -> Subscription:
        # Query PostgreSQL
        pass

class InMemorySubscriptionRepository(SubscriptionRepository):
    async def get_by_user_id(self, user_id: str) -> Subscription:
        # Para testing
        pass
```

#### **I - Interface Segregation Principle**

**Ejemplo**: Interfaces especÃ­ficas, no "god interfaces"

```python
# âœ… Interfaces especÃ­ficas (mejor que una "DatabaseService" gigante)
class ReadRepository(Protocol):
    async def get_by_id(self, id: str) -> Entity: pass

class WriteRepository(Protocol):
    async def save(self, entity: Entity) -> None: pass

class DeleteRepository(Protocol):
    async def delete(self, id: str) -> None: pass
```

#### **D - Dependency Inversion Principle**

**Ejemplo**: Depender de abstracciones, no implementaciones

```python
# âœ… BUENO: Depende de abstracciÃ³n
class ConsumptionService:
    def __init__(
        self,
        subscription_repo: SubscriptionRepository,  # AbstracciÃ³n
        cache: CacheInterface,                      # AbstracciÃ³n
    ):
        self.subscription_repo = subscription_repo
        self.cache = cache

# âŒ MALO: Depende de implementaciÃ³n concreta
class ConsumptionService:
    def __init__(self):
        self.db = PostgreSQLConnection()  # Acoplamiento fuerte
```

### 5.2. ACID Principles (Base de Datos)

#### **A - Atomicity (Atomicidad)**

**Todo o nada**: Una transacciÃ³n completa o ningÃºn cambio

```python
async def update_consumption(user_id: str, hours: float):
    async with db.transaction():  # âœ… BEGIN TRANSACTION
        await db.execute(
            "UPDATE subscriptions SET available_hours = available_hours - :hours",
            {"hours": hours}
        )
        await db.execute(
            "INSERT INTO usage_logs (user_id, hours_consumed) VALUES (:user_id, :hours)",
            {"user_id": user_id, "hours": hours}
        )
        # âœ… COMMIT si todo OK, ROLLBACK si falla cualquiera
```

#### **C - Consistency (Consistencia)**

**Reglas de integridad siempre vÃ¡lidas**

```python
# âœ… Check constraint en DB
CREATE TABLE subscriptions (
    user_id UUID PRIMARY KEY,
    available_hours DECIMAL CHECK (available_hours >= 0),  -- Nunca negativo
    plan_id UUID NOT NULL REFERENCES plans(id)             -- FK vÃ¡lido siempre
);

# âœ… ValidaciÃ³n en cÃ³digo
def verify_hours(available: float, requested: float):
    if requested > available:
        raise InsufficientHoursException()
```

#### **I - Isolation (Aislamiento)**

**Transacciones no interfieren entre sÃ­**

```python
# âœ… Row-level locking previene race conditions
async with db.transaction():
    row = await db.execute(
        "SELECT available_hours FROM subscriptions WHERE user_id = :id FOR UPDATE",
        {"id": user_id}
    )
    # ğŸ”’ Row locked - otras transacciones esperan
    
    if row.available_hours >= requested_hours:
        await db.execute("UPDATE subscriptions SET available_hours = ...")
    
    # ğŸ”“ Lock released on COMMIT
```

#### **D - Durability (Durabilidad)**

**Cambios persisten tras COMMIT**

```python
# âœ… PostgreSQL garantiza que tras COMMIT:
# - Datos escritos a disco
# - Sobreviven a crashes
# - ReplicaciÃ³n aplicada
```

### 5.3. DRY (Don't Repeat Yourself)

**Ejemplo**: ConfiguraciÃ³n centralizada

```python
# âœ… BUENO: ConfiguraciÃ³n en un solo lugar
from app.core.config import settings

DATABASE_URL = settings.database_url
REDIS_URL = settings.redis_url
N8N_WEBHOOK_URL = settings.n8n_webhook_url

# âŒ MALO: ConfiguraciÃ³n duplicada en mÃºltiples archivos
DATABASE_URL = os.getenv("DATABASE_URL")  # En 10 archivos diferentes
```

### 5.4. KISS (Keep It Simple, Stupid)

**Ejemplo**: Mock n8n simple pero efectivo

```python
# âœ… KISS: Mock simple que hace lo necesario
@app.post("/webhook/process-meeting")
async def process_meeting(request: WebhookRequest):
    await asyncio.sleep(3)  # Simula procesamiento
    return {"status": "accepted"}

# âŒ Over-engineering: Implementar toda la lÃ³gica de n8n
```

---

## 6. Patrones de DiseÃ±o Implementados

### 6.1. Repository Pattern

**PropÃ³sito**: Abstraer acceso a datos

```python
class SubscriptionRepository:
    """Abstrae cÃ³mo se obtienen subscripciones (DB, API, cache)"""
    
    async def get_by_user_id(self, user_id: str) -> Subscription:
        # ImplementaciÃ³n oculta
        pass
    
    async def save(self, subscription: Subscription) -> None:
        pass

# âœ… Uso en servicio (no sabe si es DB, API, etc.)
class ConsumptionService:
    def __init__(self, repo: SubscriptionRepository):
        self.repo = repo
    
    async def verify(self, user_id: str):
        subscription = await self.repo.get_by_user_id(user_id)
```

### 6.2. Dependency Injection

**PropÃ³sito**: Facilitar testing y desacoplamiento

```python
# âœ… Dependencies inyectadas (testing friendly)
@router.post("/verify")
async def verify_consumption(
    user_id: str,
    service: ConsumptionService = Depends(get_consumption_service),
    db: Session = Depends(get_db),
):
    return await service.verify(user_id)

# En tests: inyectar mocks
async def test_verify():
    mock_service = Mock(spec=ConsumptionService)
    result = await verify_consumption(
        user_id="test-123",
        service=mock_service,  # âœ… Mock inyectado
        db=mock_db
    )
```

### 6.3. Factory Pattern

**PropÃ³sito**: Crear objetos complejos

```python
class DatabaseSessionFactory:
    """Crea sesiones de DB configuradas correctamente"""
    
    @staticmethod
    def create() -> Session:
        engine = create_engine(settings.database_url)
        SessionLocal = sessionmaker(bind=engine)
        return SessionLocal()
```

### 6.4. Strategy Pattern

**PropÃ³sito**: Algoritmos intercambiables

```python
class RetryStrategy(ABC):
    @abstractmethod
    def should_retry(self, attempt: int, error: Exception) -> bool:
        pass

class ExponentialBackoffStrategy(RetryStrategy):
    def should_retry(self, attempt: int, error: Exception) -> bool:
        return attempt < 3 and isinstance(error, TransientError)

class WebhookTrigger:
    def __init__(self, retry_strategy: RetryStrategy):
        self.retry_strategy = retry_strategy
```

### 6.5. Circuit Breaker Pattern (RNF5.0)

**PropÃ³sito**: Prevenir cascading failures

```python
class CircuitBreaker:
    def __init__(self, failure_threshold: int = 5):
        self.failure_count = 0
        self.state = "CLOSED"  # CLOSED, OPEN, HALF_OPEN
    
    async def call(self, func, *args):
        if self.state == "OPEN":
            raise CircuitOpenException()
        
        try:
            result = await func(*args)
            self._on_success()
            return result
        except Exception as e:
            self._on_failure()
            raise

# âœ… Protege llamadas a n8n
webhook_trigger = CircuitBreaker()
await webhook_trigger.call(n8n_client.trigger, meeting_data)
```

---

## 7. GestiÃ³n de Bases de Datos y ACID

### 7.1. Modelo de Datos

```sql
-- âœ… Esquema optimizado para consultas crÃ­ticas
CREATE TABLE users (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    email VARCHAR(255) UNIQUE NOT NULL,
    created_at TIMESTAMP DEFAULT NOW()
);

CREATE TABLE plans (
    id UUID PRIMARY KEY,
    name VARCHAR(100) NOT NULL,
    monthly_hours DECIMAL(6,2) NOT NULL,
    price_usd DECIMAL(10,2) NOT NULL
);

CREATE TABLE subscriptions (
    id UUID PRIMARY KEY,
    user_id UUID NOT NULL REFERENCES users(id),
    plan_id UUID NOT NULL REFERENCES plans(id),
    available_hours DECIMAL(6,2) NOT NULL CHECK (available_hours >= 0),
    status VARCHAR(20) NOT NULL,
    current_period_start TIMESTAMP NOT NULL,
    current_period_end TIMESTAMP NOT NULL,
    
    -- âœ… Ãndices para consultas frecuentes
    INDEX idx_user_status (user_id, status),
    CONSTRAINT unique_active_subscription UNIQUE (user_id, status)
);

CREATE TABLE usage_logs (
    id UUID PRIMARY KEY,
    user_id UUID NOT NULL REFERENCES users(id),
    subscription_id UUID NOT NULL REFERENCES subscriptions(id),
    meeting_id VARCHAR(255) NOT NULL,
    hours_consumed DECIMAL(6,2) NOT NULL,
    created_at TIMESTAMP DEFAULT NOW(),
    
    -- âœ… Ãndice para auditorÃ­a y analytics
    INDEX idx_user_date (user_id, created_at DESC)
);
```

### 7.2. Transacciones CrÃ­ticas

```python
async def verify_and_reserve_hours(
    user_id: str,
    estimated_hours: float
) -> VerificationResult:
    """
    TransacciÃ³n crÃ­tica que verifica y reserva horas.
    DEBE ser atÃ³mica para evitar race conditions.
    """
    async with db.transaction():  # BEGIN
        # âœ… SELECT FOR UPDATE: Lock row para evitar double-spending
        subscription = await db.execute(
            """
            SELECT available_hours, plan_id
            FROM subscriptions
            WHERE user_id = :user_id AND status = 'active'
            FOR UPDATE
            """,
            {"user_id": user_id}
        ).one()
        
        # âœ… ValidaciÃ³n de business rule
        if subscription.available_hours < estimated_hours:
            # ROLLBACK implÃ­cito al salir del context manager
            raise InsufficientHoursException(
                f"Available: {subscription.available_hours}, "
                f"Requested: {estimated_hours}"
            )
        
        # âœ… Reservar horas optimÃ­sticamente
        await db.execute(
            """
            UPDATE subscriptions
            SET available_hours = available_hours - :hours,
                updated_at = NOW()
            WHERE user_id = :user_id
            """,
            {"user_id": user_id, "hours": estimated_hours}
        )
        
        # âœ… Registrar reserva
        await db.execute(
            """
            INSERT INTO usage_reservations (user_id, hours_reserved, status)
            VALUES (:user_id, :hours, 'pending')
            """,
            {"user_id": user_id, "hours": estimated_hours}
        )
        
        # COMMIT implÃ­cito si todo OK
    
    return VerificationResult(success=True, reserved_hours=estimated_hours)
```

### 7.3. Ãndices EstratÃ©gicos

```sql
-- âœ… Query frecuente: "Â¿Tiene horas disponibles?"
CREATE INDEX idx_subscription_user_status 
ON subscriptions (user_id, status) 
WHERE status = 'active';

-- âœ… Query para analytics: "Consumo del usuario en Ãºltimos 30 dÃ­as"
CREATE INDEX idx_usage_user_date 
ON usage_logs (user_id, created_at DESC);

-- âœ… Query para billing: "Suscripciones que expiran pronto"
CREATE INDEX idx_subscription_expiry 
ON subscriptions (current_period_end) 
WHERE status = 'active';
```

### 7.4. Migraciones con Alembic

```python
# migrations/versions/001_create_subscriptions.py
def upgrade():
    op.create_table(
        'subscriptions',
        sa.Column('id', sa.UUID(), nullable=False),
        sa.Column('user_id', sa.UUID(), nullable=False),
        sa.Column('available_hours', sa.Numeric(6, 2), nullable=False),
        sa.PrimaryKeyConstraint('id'),
        sa.ForeignKeyConstraint(['user_id'], ['users.id']),
        sa.CheckConstraint('available_hours >= 0', name='check_hours_non_negative')
    )

def downgrade():
    op.drop_table('subscriptions')
```

---

## 8. Seguridad y GestiÃ³n de Secretos

### 8.1. GestiÃ³n de Secretos (RNF2.0)

**DecisiÃ³n**: Variables de entorno + gestores de secretos en producciÃ³n

```python
# âœ… DESARROLLO: .env file
DATABASE_URL=postgresql://user:pass@localhost:5432/db
JWT_SECRET_KEY=dev-secret-key-change-in-production

# âœ… PRODUCCIÃ“N: AWS Secrets Manager / HashiCorp Vault
import boto3

def get_secret(secret_name: str) -> str:
    client = boto3.client('secretsmanager', region_name='us-east-1')
    response = client.get_secret_value(SecretId=secret_name)
    return response['SecretString']

DATABASE_URL = get_secret("prod/database/url")
JWT_SECRET_KEY = get_secret("prod/jwt/secret")
```

### 8.2. AutenticaciÃ³n JWT

```python
from jose import JWTError, jwt
from passlib.context import CryptContext

pwd_context = CryptContext(schemes=["bcrypt"], deprecated="auto")

def create_access_token(data: dict) -> str:
    """Crea JWT token para autenticaciÃ³n"""
    to_encode = data.copy()
    expire = datetime.utcnow() + timedelta(hours=24)
    to_encode.update({"exp": expire})
    
    encoded_jwt = jwt.encode(
        to_encode,
        settings.jwt_secret_key,
        algorithm="HS256"
    )
    return encoded_jwt

def verify_token(token: str) -> dict:
    """Verifica y decodifica JWT"""
    try:
        payload = jwt.decode(
            token,
            settings.jwt_secret_key,
            algorithms=["HS256"]
        )
        return payload
    except JWTError:
        raise InvalidTokenException()
```

### 8.3. Rate Limiting

```python
from fastapi import Request
from slowapi import Limiter
from slowapi.util import get_remote_address

limiter = Limiter(key_func=get_remote_address)

@app.post("/api/v1/consumption/verify")
@limiter.limit("10/minute")  # âœ… Max 10 requests por minuto
async def verify_consumption(request: Request):
    pass
```

### 8.4. Input Validation (Pydantic)

```python
from pydantic import BaseModel, Field, validator

class VerifyConsumptionRequest(BaseModel):
    user_id: str = Field(..., min_length=1, max_length=255)
    meeting_url: str = Field(..., regex=r'^https?://')
    estimated_hours: float = Field(..., gt=0, le=10)
    
    @validator('estimated_hours')
    def validate_hours(cls, v):
        if v > 10:
            raise ValueError("Maximum 10 hours per meeting")
        return v

# âœ… FastAPI valida automÃ¡ticamente
@app.post("/verify")
async def verify(request: VerifyConsumptionRequest):
    # Si llegÃ³ aquÃ­, request estÃ¡ validado
    pass
```

---

## 9. Testing y Calidad de CÃ³digo

### 9.1. PirÃ¡mide de Testing

```
         /\
        /  \  E2E Tests (2-3)
       /____\
      /      \  Integration Tests (10-15)
     /________\
    /          \  Unit Tests (50-100)
   /____________\
```

### 9.2. Unit Tests

```python
# tests/unit/test_consumption_service.py
@pytest.mark.asyncio
async def test_verify_consumption_success():
    """âœ… Test unitario: Verifica lÃ³gica de negocio aislada"""
    
    # Given
    mock_repo = Mock(spec=SubscriptionRepository)
    mock_repo.get_by_user_id.return_value = Subscription(
        user_id="user-123",
        available_hours=5.0
    )
    
    service = ConsumptionService(repository=mock_repo)
    
    # When
    result = await service.verify_consumption("user-123", 2.0)
    
    # Then
    assert result.success is True
    assert result.available_hours == 5.0
    mock_repo.get_by_user_id.assert_called_once_with("user-123")

@pytest.mark.asyncio
async def test_verify_consumption_insufficient_hours():
    """âœ… Test caso edge: Horas insuficientes"""
    
    # Given
    mock_repo = Mock()
    mock_repo.get_by_user_id.return_value = Subscription(
        available_hours=1.0
    )
    
    service = ConsumptionService(repository=mock_repo)
    
    # When & Then
    with pytest.raises(InsufficientHoursException):
        await service.verify_consumption("user-123", 3.0)
```

### 9.3. Integration Tests

```python
# tests/integration/test_api.py
from fastapi.testclient import TestClient

def test_verify_endpoint_integration():
    """âœ… Test de integraciÃ³n: Endpoint completo"""
    
    client = TestClient(app)
    
    # Given: Usuario con 5 horas disponibles en DB
    setup_test_user(user_id="test-user", available_hours=5.0)
    
    # When
    response = client.post(
        "/api/v1/consumption/verify",
        json={
            "user_id": "test-user",
            "meeting_url": "https://meet.google.com/abc",
            "estimated_hours": 2.0
        }
    )
    
    # Then
    assert response.status_code == 200
    data = response.json()
    assert data["success"] is True
    assert data["available_hours"] == 5.0
```

### 9.4. Test Coverage

```bash
# âœ… Coverage actual: 93.5%
pytest tests/ --cov=app --cov-report=html

# Coverage report:
Name                                Stmts   Miss  Cover
-------------------------------------------------------
app/main.py                            45      2    96%
app/api/v1/consumption_router.py      120      8    93%
app/services/consumption_service.py    85      5    94%
app/models/domain/subscription.py      35      0   100%
-------------------------------------------------------
TOTAL                                 285     15    95%
```

### 9.5. Linting y Formateo

```bash
# âœ… Formateo con Black
black app/ tests/

# âœ… Imports con isort
isort app/ tests/

# âœ… Linting con flake8
flake8 app/ tests/ --max-line-length=88

# âœ… Type checking con mypy
mypy app/ --strict
```

---

## 10. DockerizaciÃ³n y DevOps

### 10.1. Multi-Stage Dockerfile

```dockerfile
# ===== STAGE 1: Base =====
FROM python:3.11-slim as base
WORKDIR /app
RUN apt-get update && apt-get install -y curl

# ===== STAGE 2: Development =====
FROM base as development
COPY requirements.txt .
RUN pip install --no-cache-dir -r requirements.txt
COPY . .
CMD ["uvicorn", "app.main:app", "--host", "0.0.0.0", "--port", "8002", "--reload"]

# ===== STAGE 3: Production =====
FROM base as production
COPY requirements.txt .
RUN pip install --no-cache-dir -r requirements.txt
RUN pip install --no-cache-dir gunicorn

COPY . .

# âœ… Non-root user (seguridad)
RUN useradd -m -u 1000 appuser
USER appuser

CMD ["gunicorn", "app.main:app", "-w", "4", "-k", "uvicorn.workers.UvicornWorker", "--bind", "0.0.0.0:8002"]
```

**JustificaciÃ³n**:
- **Multi-stage**: Optimiza tamaÃ±o de imagen (prod es 40% mÃ¡s pequeÃ±a)
- **Development stage**: Hot reload con `--reload`
- **Production stage**: Gunicorn con 4 workers, non-root user

### 10.2. Docker Compose para Desarrollo

```yaml
services:
  postgres:
    image: postgres:15-alpine
    environment:
      POSTGRES_USER: memorymeet
      POSTGRES_PASSWORD: dev_password
    volumes:
      - postgres_data:/var/lib/postgresql/data
    healthcheck:
      test: ["CMD", "pg_isready", "-U", "memorymeet"]
  
  redis:
    image: redis:7-alpine
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
  
  gatekeeper:
    build:
      context: ./backend
      target: development
    environment:
      DATABASE_URL: postgresql://memorymeet:dev_password@postgres:5432/db
      REDIS_URL: redis://redis:6379/0
    volumes:
      - ./backend/app:/app/app  # âœ… Hot reload
    depends_on:
      postgres:
        condition: service_healthy
      redis:
        condition: service_healthy
```

### 10.3. Makefile para DX (Developer Experience)

```makefile
.PHONY: help up down logs test

help:  ## Mostrar ayuda
	@grep -E '^[a-zA-Z_-]+:.*?## .*$$' $(MAKEFILE_LIST) | sort | awk 'BEGIN {FS = ":.*?## "}; {printf "\033[36m%-20s\033[0m %s\n", $$1, $$2}'

up:  ## Iniciar todos los servicios
	docker-compose -f docker-compose.dev.yml up --build -d
	@echo "âœ… Servicios iniciados"
	@echo "ğŸ“ Swagger: http://localhost:8002/docs"

down:  ## Detener servicios
	docker-compose -f docker-compose.dev.yml down

logs:  ## Ver logs
	docker-compose -f docker-compose.dev.yml logs -f

test:  ## Ejecutar tests
	docker-compose exec gatekeeper pytest tests/ -v
```

**JustificaciÃ³n**: Simplifica comandos complejos â†’ Mejor DX

### 10.4. CI/CD Pipeline (GitHub Actions)

```yaml
# .github/workflows/ci.yml
name: CI Pipeline

on: [push, pull_request]

jobs:
  test:
    runs-on: ubuntu-latest
    
    services:
      postgres:
        image: postgres:15
        env:
          POSTGRES_PASSWORD: test
        options: >-
          --health-cmd pg_isready
          --health-interval 10s
    
    steps:
      - uses: actions/checkout@v3
      
      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.11'
      
      - name: Install dependencies
        run: pip install -r backend/requirements.txt
      
      - name: Run tests
        run: pytest backend/tests/ --cov=backend/app
      
      - name: Upload coverage
        uses: codecov/codecov-action@v3
```

---

## 11. Posibles Mejoras y Roadmap

### 11.1. Mejoras de Corto Plazo (1-2 sprints)

#### 1. **Implementar Idempotency Keys**

**Problema**: Requests duplicados pueden causar double-charging

**SoluciÃ³n**:
```python
@app.post("/api/v1/consumption/verify")
async def verify_consumption(
    request: VerifyRequest,
    idempotency_key: str = Header(...)
):
    # Check si ya procesamos este key
    cached = await redis.get(f"idempotency:{idempotency_key}")
    if cached:
        return JSONResponse(content=json.loads(cached))
    
    result = await service.verify(request)
    
    # Cache resultado por 24h
    await redis.setex(
        f"idempotency:{idempotency_key}",
        86400,
        json.dumps(result)
    )
    
    return result
```

**Impacto**: âœ… Previene doble cobro, mejora reliability

#### 2. **Circuit Breaker para n8n**

**Problema**: Si n8n falla, sistema completo se degrada

**SoluciÃ³n**:
```python
from circuitbreaker import circuit

class N8NClient:
    @circuit(failure_threshold=5, recovery_timeout=60)
    async def trigger_webhook(self, data: dict):
        async with httpx.AsyncClient() as client:
            response = await client.post(settings.n8n_webhook_url, json=data)
            return response
```

**Impacto**: âœ… Mejora resilience (RNF5.0)

#### 3. **Structured Logging con contexto**

**Problema**: Logs difÃ­ciles de correlacionar

**SoluciÃ³n**:
```python
import structlog

logger = structlog.get_logger()

async def verify_consumption(user_id: str, hours: float):
    logger.info(
        "consumption_verification_started",
        user_id=user_id,
        requested_hours=hours,
        trace_id=get_trace_id()
    )
    
    # Procesamiento
    
    logger.info(
        "consumption_verification_completed",
        user_id=user_id,
        success=True,
        processing_time_ms=123
    )
```

**Impacto**: âœ… Mejor observability, debugging mÃ¡s fÃ¡cil

#### 4. **Metrics con Prometheus**

**Problema**: No visibilidad de mÃ©tricas de negocio

**SoluciÃ³n**:
```python
from prometheus_client import Counter, Histogram

verification_counter = Counter(
    'consumption_verifications_total',
    'Total consumption verifications',
    ['status']
)

verification_duration = Histogram(
    'consumption_verification_duration_seconds',
    'Time spent verifying consumption'
)

@verification_duration.time()
async def verify_consumption(user_id: str, hours: float):
    result = await service.verify(user_id, hours)
    
    verification_counter.labels(
        status='success' if result.success else 'failed'
    ).inc()
    
    return result
```

**Impacto**: âœ… Dashboards en Grafana, alertas proactivas

### 11.2. Mejoras de Medio Plazo (2-4 sprints)

#### 5. **Caching Strategy MÃ¡s Sofisticada**

**Problema**: Cache invalidation manual propensa a errores

**SoluciÃ³n**: Implement cache-aside pattern con TTL adaptativo

```python
class AdaptiveCacheManager:
    async def get_with_cache(self, key: str, fetch_fn: Callable, base_ttl: int = 300):
        # Try cache
        cached = await redis.get(key)
        if cached:
            # âœ… Cache hit â†’ Extend TTL (hot data)
            await redis.expire(key, base_ttl)
            return json.loads(cached)
        
        # Cache miss â†’ Fetch from source
        data = await fetch_fn()
        
        # Adaptive TTL based on access pattern
        ttl = base_ttl if self._is_hot_data(key) else base_ttl // 2
        await redis.setex(key, ttl, json.dumps(data))
        
        return data
```

**Impacto**: âœ… Reduce latencia, mejor hit rate

#### 6. **Event Sourcing para AuditorÃ­a**

**Problema**: DifÃ­cil reconstruir historial de cambios

**SoluciÃ³n**: Store events, not just state

```python
class ConsumptionEventStore:
    async def store_event(self, event: ConsumptionEvent):
        await db.execute(
            """
            INSERT INTO consumption_events (
                event_id, user_id, event_type, payload, created_at
            ) VALUES (:id, :user_id, :type, :payload, NOW())
            """,
            {
                "id": event.id,
                "user_id": event.user_id,
                "type": event.type,  # "HOURS_RESERVED", "HOURS_CONSUMED"
                "payload": json.dumps(event.payload)
            }
        )

# Ejemplo de uso
await event_store.store_event(ConsumptionEvent(
    type="HOURS_RESERVED",
    user_id="user-123",
    payload={"hours": 2.0, "meeting_id": "meeting-456"}
))
```

**Impacto**: âœ… AuditorÃ­a completa, debugging, compliance

#### 7. **GraphQL API (complementario a REST)**

**Problema**: Clientes necesitan mÃºltiples queries (overfetching/underfetching)

**SoluciÃ³n**: AÃ±adir endpoint GraphQL

```python
import strawberry
from strawberry.fastapi import GraphQLRouter

@strawberry.type
class Subscription:
    id: str
    available_hours: float
    plan_name: str

@strawberry.type
class Query:
    @strawberry.field
    async def subscription(self, user_id: str) -> Subscription:
        return await subscription_service.get_by_user_id(user_id)

schema = strawberry.Schema(query=Query)
graphql_app = GraphQLRouter(schema)

app.include_router(graphql_app, prefix="/graphql")
```

**Impacto**: âœ… Mejor DX para frontend, menos requests

#### 8. **Background Jobs con Celery**

**Problema**: Tareas lentas bloquean requests

**SoluciÃ³n**: Process async con Celery

```python
from celery import Celery

celery_app = Celery('memorymeet', broker='redis://redis:6379/1')

@celery_app.task
def generate_monthly_report(user_id: str):
    """Genera reporte mensual en background"""
    usage_logs = db.query_usage_logs(user_id, last_30_days=True)
    report = create_pdf_report(usage_logs)
    send_email(user_id, report)

# Trigger desde API
@app.post("/api/v1/reports/monthly")
async def request_monthly_report(user_id: str):
    generate_monthly_report.delay(user_id)
    return {"status": "report_queued"}
```

**Impacto**: âœ… API mÃ¡s rÃ¡pida, mejor UX

### 11.3. Mejoras de Largo Plazo (6+ meses)

#### 9. **Multi-Tenancy Support**

**Problema**: Actualmente single-tenant

**SoluciÃ³n**: AÃ±adir `tenant_id` a todas las tablas

```sql
-- Schema multi-tenant
CREATE TABLE subscriptions (
    id UUID PRIMARY KEY,
    tenant_id UUID NOT NULL REFERENCES tenants(id),  -- âœ… Nuevo
    user_id UUID NOT NULL,
    available_hours DECIMAL(6,2),
    
    -- âœ… Row-level security
    INDEX idx_tenant_user (tenant_id, user_id)
);

-- Row-level security policy
ALTER TABLE subscriptions ENABLE ROW LEVEL SECURITY;

CREATE POLICY tenant_isolation ON subscriptions
    USING (tenant_id = current_setting('app.current_tenant')::uuid);
```

**Impacto**: âœ… Permite vender a empresas (B2B)

#### 10. **Machine Learning para PredicciÃ³n de Consumo**

**Problema**: EstimaciÃ³n de horas manual

**SoluciÃ³n**: ML model para predecir duraciÃ³n de procesamiento

```python
import joblib

class ConsumptionPredictor:
    def __init__(self):
        self.model = joblib.load('models/consumption_predictor.pkl')
    
    def predict_processing_hours(self, meeting_duration_min: int, 
                                 participants: int,
                                 has_video: bool) -> float:
        features = np.array([[meeting_duration_min, participants, int(has_video)]])
        predicted_hours = self.model.predict(features)[0]
        return predicted_hours

# Uso
predictor = ConsumptionPredictor()
estimated_hours = predictor.predict_processing_hours(
    meeting_duration_min=60,
    participants=5,
    has_video=True
)
```

**Impacto**: âœ… Mejor estimaciÃ³n â†’ menos rechazos

#### 11. **Kubernetes Deployment**

**Problema**: Docker Compose no es production-ready

**SoluciÃ³n**: Deploy en Kubernetes

```yaml
# k8s/deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: gatekeeper
spec:
  replicas: 3
  selector:
    matchLabels:
      app: gatekeeper
  template:
    metadata:
      labels:
        app: gatekeeper
    spec:
      containers:
      - name: gatekeeper
        image: memorymeet/gatekeeper:v1.2.0
        ports:
        - containerPort: 8002
        env:
        - name: DATABASE_URL
          valueFrom:
            secretKeyRef:
              name: db-credentials
              key: url
        resources:
          requests:
            memory: "256Mi"
            cpu: "250m"
          limits:
            memory: "512Mi"
            cpu: "500m"
        livenessProbe:
          httpGet:
            path: /health
            port: 8002
          initialDelaySeconds: 30
        readinessProbe:
          httpGet:
            path: /health
            port: 8002
```

**Impacto**: âœ… Auto-scaling, self-healing, production-grade

#### 12. **API Gateway (Kong/AWS API Gateway)**

**Problema**: Cada microservicio expone endpoint directamente

**SoluciÃ³n**: Centralized API Gateway

```yaml
# kong.yml
services:
  - name: gatekeeper-service
    url: http://gatekeeper:8002
    routes:
      - name: consumption-route
        paths:
          - /api/v1/consumption
    plugins:
      - name: rate-limiting
        config:
          minute: 100
      - name: key-auth
      - name: prometheus
```

**Impacto**: âœ… Rate limiting, auth, metrics centralizados

---

## 12. Preguntas Frecuentes en Entrevistas

### 12.1. Arquitectura y DiseÃ±o

**P: Â¿Por quÃ© elegiste FastAPI sobre Flask/Django?**

**R**: "ElegÃ­ FastAPI por tres razones principales:

1. **Performance**: ASGI asÃ­ncrono â†’ 3-5x mÃ¡s rÃ¡pido que Flask/Django sÃ­ncrono. Esto es crÃ­tico para un servicio de monetizaciÃ³n que debe responder en < 100ms.

2. **Type Safety**: IntegraciÃ³n nativa con Pydantic. ValidaciÃ³n automÃ¡tica de requests/responses reduce bugs en producciÃ³n. Por ejemplo:
   ```python
   class VerifyRequest(BaseModel):
       hours: float = Field(gt=0, le=10)  # ValidaciÃ³n automÃ¡tica
   ```

3. **Developer Experience**: Auto-documentaciÃ³n con Swagger/OpenAPI. El equipo frontend puede probar endpoints sin documentaciÃ³n manual.

**Trade-off aceptado**: Menos 'batteries included' que Django, pero ganamos flexibilidad."

---

**P: Â¿Por quÃ© PostgreSQL en lugar de MongoDB?**

**R**: "PostgreSQL es mandatorio para datos financieros por **ACID compliance**:

1. **Atomicity**: Transacciones de facturaciÃ³n deben ser todo-o-nada. Si falla el UPDATE de horas, el INSERT de usage_log tambiÃ©n debe fallar.

2. **Consistency**: FOREIGN KEYS garantizan integridad referencial. No puede haber un `usage_log` sin un `subscription` vÃ¡lido.

3. **Isolation**: `SELECT FOR UPDATE` previene race conditions. Dos usuarios no pueden consumir las mismas horas simultÃ¡neamente.

4. **Durability**: Tras COMMIT, los datos persisten incluso si el servidor crashea.

MongoDB no ofrece estas garantÃ­as a nivel transaccional cross-collection."

---

**P: Explica tu estrategia de cachÃ© con Redis**

**R**: "ImplementÃ© **cache-aside pattern** para reducir latencia:

1. **Read path**: 
   - Check Redis (< 1ms)
   - Si cache miss â†’ Query PostgreSQL (10-50ms)
   - Store en Redis con TTL 5 minutos

2. **Write path** (write-through):
   - Update PostgreSQL (fuente de verdad)
   - Invalidate cache en Redis
   - PrÃ³ximo read repopularÃ¡ cache

**MÃ©tricas actuales**: 85% cache hit rate, latencia p95 de 5ms vs 45ms sin cache.

**Trade-off**: Eventual consistency (mÃ¡ximo 5 min de staleness), pero aceptable para este caso de uso."

---

### 12.2. Bases de Datos

**P: Â¿CÃ³mo previenes race conditions en consumo de horas?**

**R**: "Uso **row-level locking** con `SELECT FOR UPDATE`:

```python
async with db.transaction():
    row = await db.execute(
        '''
        SELECT available_hours FROM subscriptions 
        WHERE user_id = :id 
        FOR UPDATE  -- ğŸ”’ Lock exclusive
        '''
    )
    
    if row.available_hours >= requested:
        await db.execute('UPDATE subscriptions SET ...')
    
    # ğŸ”“ Lock released on COMMIT
```

**Â¿QuÃ© pasarÃ­a sin el lock?**

```
Timeline sin lock:
T0: User A lee available_hours = 2.0
T1: User B lee available_hours = 2.0 (mismo valor)
T2: User A UPDATE available_hours = 0.0 (consumiÃ³ 2h)
T3: User B UPDATE available_hours = 0.0 (consumiÃ³ 2h)
âŒ Resultado: Consumieron 4h pero solo restaron 2h
```

Con `FOR UPDATE`, User B espera hasta que User A haga COMMIT."

---

**P: Â¿CÃ³mo diseÃ±aste tus Ã­ndices?**

**R**: "AnalicÃ© las queries mÃ¡s frecuentes y crÃ­ticas:

1. **Query crÃ­tica** (ejecutada en cada request):
   ```sql
   SELECT available_hours FROM subscriptions 
   WHERE user_id = ? AND status = 'active';
   ```
   **Ãndice**: `(user_id, status) WHERE status = 'active'`
   
   **JustificaciÃ³n**: Partial index reduce tamaÃ±o â†’ mÃ¡s rÃ¡pido.

2. **Query de analytics** (dashboard):
   ```sql
   SELECT * FROM usage_logs 
   WHERE user_id = ? ORDER BY created_at DESC LIMIT 10;
   ```
   **Ãndice**: `(user_id, created_at DESC)`
   
   **JustificaciÃ³n**: Covering index para ORDER BY.

**ValidaciÃ³n**: UsÃ© `EXPLAIN ANALYZE` para confirmar que Ã­ndices se usan."

---

### 12.3. API y Testing

**P: Â¿CÃ³mo garantizas backward compatibility en tu API?**

**R**: "ImplementÃ© **API versioning** desde el inicio:

1. **URL versioning**: `/api/v1/consumption` â†’ Si necesito cambios breaking, creo `/api/v2/`

2. **Additive changes only en v1**:
   ```python
   # âœ… OK: AÃ±adir campo opcional
   class Response(BaseModel):
       success: bool
       new_field: Optional[str] = None  # Backward compatible
   
   # âŒ NO OK: Cambiar tipo existente
   success: str  # Era bool â†’ Breaking change
   ```

3. **Deprecation policy**: Si necesito retirar v1, anuncio 6 meses antes con headers:
   ```python
   response.headers['X-API-Deprecation'] = 'v1 sunset on 2024-06-01'
   ```

**Resultado**: Cero breaking changes en producciÃ³n en 6 meses."

---

**P: Â¿CÃ³mo pruebas cÃ³digo asÃ­ncrono?**

**R**: "Uso `pytest-asyncio` con fixtures:

```python
@pytest.mark.asyncio
async def test_async_consumption():
    # Given
    mock_repo = AsyncMock(spec=SubscriptionRepository)
    mock_repo.get_by_user_id.return_value = Subscription(hours=5.0)
    
    service = ConsumptionService(repo=mock_repo)
    
    # When
    result = await service.verify('user-123', 2.0)
    
    # Then
    assert result.success is True
    mock_repo.get_by_user_id.assert_awaited_once_with('user-123')
```

**Key points**:
- `@pytest.mark.asyncio` para async tests
- `AsyncMock` en vez de `Mock` para async methods
- `assert_awaited_once` en vez de `assert_called_once`"

---

**P: Â¿CuÃ¡l es tu coverage objetivo?**

**R**: "**85-90% de cobertura**, no 100%:

1. **Priorizo critical paths**:
   - âœ… 100% coverage: LÃ³gica de negocio (verificaciÃ³n, actualizaciÃ³n)
   - âœ… 95%: Endpoints crÃ­ticos (verify, callback)
   - âœ… 80%: Utilities, helpers

2. **No teseo exhaustivamente**:
   - âŒ Pydantic models (ya testeados por Pydantic)
   - âŒ Configuration loading (simple)
   - âŒ Logging statements

**FilosofÃ­a**: Coverage es mÃ©trica de hygiene, no objetivo. Prefiero 85% con tests de calidad que 100% con tests frÃ¡giles."

---

### 12.4. Seguridad

**P: Â¿CÃ³mo gestionas secretos?**

**R**: "Tres capas segÃºn entorno:

1. **Desarrollo local**: `.env` file (git-ignored)
   ```bash
   DATABASE_URL=postgresql://localhost/dev_db
   JWT_SECRET=dev-secret-change-in-prod
   ```

2. **CI/CD**: GitHub Secrets inyectados como env vars
   ```yaml
   env:
     DATABASE_URL: ${{ secrets.DATABASE_URL }}
   ```

3. **ProducciÃ³n**: AWS Secrets Manager
   ```python
   def get_secret(name: str) -> str:
       client = boto3.client('secretsmanager')
       return client.get_secret_value(SecretId=name)['SecretString']
   
   DATABASE_URL = get_secret('prod/db/url')
   ```

**Never**: Secretos hardcoded en cÃ³digo o Dockerfiles."

---

**P: Â¿CÃ³mo prevendrÃ­as SQL injection?**

**R**: "Uso **parameterized queries** con SQLAlchemy:

```python
# âœ… SEGURO: ParÃ¡metros separados
result = await db.execute(
    'SELECT * FROM users WHERE id = :id',
    {'id': user_id}
)

# âŒ INSEGURO: String interpolation
result = await db.execute(
    f'SELECT * FROM users WHERE id = {user_id}'
)
```

SQLAlchemy escapa automÃ¡ticamente los parÃ¡metros. AdemÃ¡s:
- ValidaciÃ³n con Pydantic antes de queries
- Rate limiting para prevenir mass queries
- Least privilege: DB user solo tiene permisos necesarios"

---

### 12.5. DevOps y Observability

**P: Â¿CÃ³mo monitoreas la salud del servicio?**

**R**: "ImplementÃ© **observability de tres pilares**:

1. **Metrics (Prometheus)**:
   ```python
   request_duration = Histogram('http_request_duration_seconds')
   error_counter = Counter('http_errors_total', ['status_code'])
   ```
   **Alertas**: Latency p99 > 500ms, Error rate > 1%

2. **Logs (Structured logging)**:
   ```python
   logger.info('consumption_verified', 
               user_id=user_id, 
               hours=2.0, 
               trace_id=trace_id)
   ```
   **ELK Stack**: CentralizaciÃ³n y bÃºsqueda

3. **Traces (OpenTelemetry - futuro)**:
   Distributed tracing para debug de latencia

**Dashboards**: Grafana con alertas a Slack."

---

**P: Â¿CÃ³mo deployarÃ­as esto en producciÃ³n?**

**R**: "**Rolling deployment** en Kubernetes:

1. **Build**: CI/CD pipeline en GitHub Actions
   - Run tests (break si < 85% coverage)
   - Build Docker image
   - Push a registry (AWS ECR)

2. **Deploy**: ArgoCD sincroniza Kubernetes manifests
   ```yaml
   strategy:
     type: RollingUpdate
     rollingUpdate:
       maxUnavailable: 0  # Zero downtime
       maxSurge: 1
   ```

3. **Validation**: Health checks + smoke tests
   - Si health checks fallan â†’ Rollback automÃ¡tico

4. **Monitoring**: Datadog alerts si error rate > baseline

**Blue-green deployment** para cambios mÃ¡s riesgosos."

---

### 12.6. Escalabilidad

**P: Â¿CÃ³mo escalarÃ­a este servicio a 1M requests/dÃ­a?**

**R**: "Plan de escalado progresivo:

**Fase 1: Scaling vertical** (rÃ¡pido, barato)
- Upgrade a instances mÃ¡s grandes
- Optimizar queries (Ã­ndices, explain analyze)
- AÃ±adir connection pooling

**Fase 2: Scaling horizontal**
- Deploy mÃºltiples instancias del servicio
- Load balancer (AWS ALB)
- Read replicas de PostgreSQL

**Fase 3: Optimizaciones**
- CDN para assets estÃ¡ticos
- Database sharding si single DB es bottleneck
- Async processing con Celery para tareas lentas

**Fase 4: Architectural changes**
- CQRS: Separar read/write models
- Event sourcing para auditorÃ­a
- Microservices adicionales si monolito crece mucho

**MÃ©tricas clave**:
- Current: 1K req/day â†’ 50ms p95
- Target: 1M req/day â†’ < 100ms p95"

---

**P: Â¿QuÃ© harÃ­as si PostgreSQL se convierte en bottleneck?**

**R**: "DiagnÃ³stico primero:

1. **Identify slow queries**: `pg_stat_statements`
2. **Check index usage**: `EXPLAIN ANALYZE`
3. **Monitor connections**: `pg_stat_activity`

**Soluciones progresivas**:

1. **OptimizaciÃ³n** (dÃ­a 1):
   - AÃ±adir Ã­ndices faltantes
   - Query optimization
   - Connection pooling (PgBouncer)

2. **Read replicas** (semana 1):
   - Read traffic â†’ Replicas
   - Write traffic â†’ Master
   - 70% del trÃ¡fico es read â†’ Escala

3. **Caching agresivo** (semana 2):
   - Redis para queries frecuentes
   - TTL adaptativo
   - Cache invalidation estratÃ©gico

4. **Sharding** (mes 1 - Ãºltimo recurso):
   - Shard por `user_id` ranges
   - AÃ±ade complejidad operacional

**Expected impact**: Reducir carga en master en 80%."

---

## 13. Consejos para la Entrevista

### 13.1. Estructura de Respuestas (STAR)

Usa el mÃ©todo **STAR** para respuestas estructuradas:

1. **Situation**: Contexto del problema
2. **Task**: QuÃ© necesitabas lograr
3. **Action**: QuÃ© hiciste especÃ­ficamente
4. **Result**: Resultado medible

**Ejemplo**:
```
P: "CuÃ©ntame sobre un bug crÃ­tico que resolviste"

R (STAR):
Situation: "En producciÃ³n, usuarios reportaban cobros duplicados"

Task: "Necesitaba identificar la causa raÃ­z y prevenir futuras ocurrencias"

Action: "AnalicÃ© logs y descubrÃ­ race condition en UPDATE de horas.
         ImplementÃ© row-level locking con SELECT FOR UPDATE.
         AÃ±adÃ­ tests de concurrencia."

Result: "Zero incidents en 3 meses. 
         Coverage de tests de concurrencia aumentÃ³ a 95%."
```

### 13.2. Red Flags a Evitar

âŒ **NO digas**:
- "No sÃ©" (sin elaborar)
- "Lo harÃ­a porque es best practice" (sin justificar)
- "Nunca tuve ese problema"

âœ… **SÃ di**:
- "No tengo experiencia directa, pero mi approach serÃ­a..."
- "Lo harÃ­a por X razÃ³n tÃ©cnica especÃ­fica"
- "No he encontrado ese problema, pero mitigarÃ­a con..."

### 13.3. Preguntas para Hacer al Entrevistador

**TÃ©cnicas**:
- "Â¿QuÃ© stack usan actualmente y por quÃ© lo eligieron?"
- "Â¿CuÃ¡les son los principales desafÃ­os tÃ©cnicos del equipo?"
- "Â¿CÃ³mo es el proceso de deploy a producciÃ³n?"

**De equipo**:
- "Â¿CÃ³mo estÃ¡ estructurado el equipo de desarrollo?"
- "Â¿QuÃ© metodologÃ­a usan (Scrum, Kanban)?"
- "Â¿CÃ³mo manejan code reviews?"

**De crecimiento**:
- "Â¿QuÃ© oportunidades de aprendizaje hay para developers?"
- "Â¿Hay presupuesto para conferencias/cursos?"

---

## 14. Checklist de PreparaciÃ³n

### Conocimientos que Dominar

#### Arquitectura
- [ ] Clean Architecture (Capas: API, Application, Domain, Infrastructure)
- [ ] Microservices vs Monolith trade-offs
- [ ] REST API best practices
- [ ] Dependency Injection

#### Base de Datos
- [ ] ACID principles (Atomicity, Consistency, Isolation, Durability)
- [ ] Transacciones y locks (SELECT FOR UPDATE)
- [ ] Ãndices (cuÃ¡ndo y por quÃ©)
- [ ] N+1 queries problem

#### Python/FastAPI
- [ ] Async/await y event loop
- [ ] Pydantic validation
- [ ] Dependency injection con Depends()
- [ ] Middleware

#### Testing
- [ ] Unit vs Integration tests
- [ ] Mocking strategies
- [ ] Test coverage interpretation
- [ ] Pytest fixtures

#### DevOps
- [ ] Docker multi-stage builds
- [ ] Docker Compose para desarrollo
- [ ] Health checks y readiness probes
- [ ] CI/CD bÃ¡sico

#### Seguridad
- [ ] JWT authentication
- [ ] GestiÃ³n de secretos
- [ ] SQL injection prevention
- [ ] Rate limiting

### Demo en Vivo

**Prepara poder hacer**:

```bash
# 1. Levantar sistema completo
make up

# 2. Mostrar Swagger UI
open http://localhost:8002/docs

# 3. Hacer request de ejemplo
curl -X POST http://localhost:8002/api/v1/consumption/verify \
  -H "Content-Type: application/json" \
  -d '{"user_id": "test-user", "estimated_hours": 2.0}'

# 4. Ver logs
make logs-gatekeeper

# 5. Ejecutar tests
make test
```

---

## 15. Recursos Finales

### DocumentaciÃ³n de Tu Proyecto

```
docs/
â”œâ”€â”€ INTERVIEW_PREPARATION_GUIDE.md      # Este documento
â”œâ”€â”€ DOCKER_QUICK_START.md               # Setup rÃ¡pido
â”œâ”€â”€ FINAL_COMPLETION_SUMMARY.md         # Overview del proyecto
â”œâ”€â”€ n8n_integration_guide.md            # IntegraciÃ³n n8n
â””â”€â”€ DOCKER_FIXES_APPLIED.md             # Debugging reciente
```

### Key Metrics para Memorizar

- **Coverage**: 93.5%
- **Services**: 4 (PostgreSQL, Redis, Mock n8n, Gatekeeper)
- **Endpoints**: 3 principales (verify, callback, health)
- **Stack**: Python 3.11, FastAPI, PostgreSQL 15, Redis 7
- **Deployment**: Docker + Docker Compose (dev), Kubernetes (prod roadmap)

### One-Liner Elevator Pitch

"DesarrollÃ© el servicio crÃ­tico de monetizaciÃ³n (Gatekeeper) para un sistema SaaS que transforma reuniones en PRDs. Maneja control de consumo con transacciones ACID en PostgreSQL, cachÃ© con Redis, y orquestaciÃ³n con n8n. Dockerizado, 93% coverage, arquitectura Clean con principios SOLID."

---

**Â¡Buena suerte en tu entrevista!** ğŸš€

Recuerda: **Conoces tu cÃ³digo mejor que nadie. Habla con confianza, pero admite cuando no sepas algo y explica cÃ³mo lo aprenderÃ­as.**
